= V4 Outline MultiLine NoSorting TabWidth=30

H="Project Notes"

********************HEADING******************** 

Project Name: Katherine's P01 [tentative]

Date Started: 2/19

Primary Investigator: Katherine Ornstein
Funding Source: ?

Created by: OKR

Primary Analyst: OKR
Secondary Analyst: ??

Datasets Used: NHATS, NHATS-linked Medicare claims, HRS, HRS Medicare, HRS MAX

Simple Outline:  Looking at the receipt of Home Based Medical Care (HBMC) within people with Dementia 


*/
 
//STATA
// Global Macros use $ symbol to be called. 

//Intermediate Data Path
global intpath "E:\data\HBMC_HRS\int_data"

// Final Data Path
global datapath "E:\nhats\data\Projects\serious_ill\icd910\final_data"

//Working Log files path
global logpath "E:\data\HBMC_HRS\logs"

//Final Logs Path

"E:\data\projects\HBMC_HRS\logs"

//SAS 

/*nhats cleaned path*/
libname nhats 'E:\nhats\data\NHATS cleaned';

/*medicare xwalk and claims path*/
libname medi 'E:\nhats\data\20180625 NHATS CMS Data\merged';


H="********"


H="Data Setup"
use "E:\data\hrs_cleaned\core_00_to_14.dta" , clear 

merge 1:1 id core_year using "E:\data\HBMC_HRS\int_data\hrs_housecalls.dta"

/* Only keeping most recent ivws for people without housecall */

gen hcall = .
preserve
keep if _m==3
replace hcall = 1
drop _m
tempfile hcalls
save `hcalls'
restore

levelsof id if _m==3, local(match)

foreach x of local match {
replace hcall= 1 if id=="`x'"
}

drop _m
drop if hcall==1
gsort id -core_year
by id: keep if _n==1

append using "`hcalls'"

replace hcall = 0 if hcall==.
label var hcall "Medicare House call +/- 90 days of iw"

save "E:\data\HBMC_HRS\int_data\hrs_merged.dta", replace

use "E:\data\HBMC_HRS\int_data\hrs_merged.dta", replace

drop bid_hrs_22

merge 1:1 hhid pn using "E:\data\CMS_DUA_51675_2014\Merged\Stata\xref2015medicare.dta", keepus(BID_HRS_22)
drop if _m==2

gen mcare_claims = 0
replace mcare_claims = 1 if BID_HRS_22!=""
label var mcare_claims "Has Medicare Claims"
cap drop _m

merge 1:1 hhid pn using "E:\data\CMS_DUA_51675_2014\Medicaid_merged\MedicaidXref2012.dta", keepus(bid_hrs_23)
drop if _m==2

gen maid_claims = 0
replace maid_claims = 1 if _m==3
label var maid_claims "Has Medicaid Claims"
drop _m

merge 1:1 id using "E:\data\HBMC_HRS\int_data\any_maid_hh.dta", keepus(maid_hh)
replace maid_hh = 0 if maid_hh==.
label var maid_hh "Has any Medicaid HH claim"
drop _m

rename *, l

save "E:\data\HBMC_HRS\int_data\hrs_merged2.dta", replace 

use "E:\data\CMS_DUA_51675_2014\Merged\Stata\hh_1998_2015.dta", clear
keep bid_hrs_22
duplicates drop

tempfile mcarehh
save `mcarehh'

use "E:\data\HBMC_HRS\int_data\hrs_merged2.dta", replace 


preserve
keep if bid_hrs_22==""
tempfile applater
save `applater'
restore 

drop if bid_hrs_22==""

merge 1:m bid_hrs_22 using "`mcarehh'", keepus(bid_hrs_22)
drop if _m==2

gen mcare_hh = .
replace mcare_hh = 1 if _m==3

append using "`applater'"

replace mcare_hh = 0 if mcare_hh==.
label var mcare_hh "Has any Medicare HH claim"
drop _m

save "E:\data\HBMC_HRS\int_data\hrs_merged2.dta", replace  

/* Merge with rest. tracker for demographics */

use "E:\data\HBMC_HRS\int_data\hrs_merged2.dta", replace  

merge m:1 hhid pn using "E:\data\hrs_cleaned\restr_tracker_v2014.dta", keepus(birth_date hisp_eth white black degree gender)
drop if _m==2
drop _m

cap drop female
gen female = 0 if gender!=.
replace female = 1 if gender==2

gen age = ((c_ivw_date - birth_date)/365.25)
replace age = ceil(age)

gen livealone = 0 if hhm!=. & nhres!=1
replace livealone = 1 if hhm==0

gen adl_dep_core = 0 if adl_index_core!=.
replace adl_dep_core = 1 if  adl_index_core>0 & adl_index_core!=.
label var adl_dep_core "ADL dependent at core"

gen iadl_dep_core = 0 if iadl_ind_core!=.
replace iadl_dep_core = 1 if  iadl_ind_core>0 & iadl_ind_core!=.
label var iadl_dep_core "IADL dependent at core"

gen all = 1

replace hseduc = 0
replace hseduc = 1 if degree>0


local ivars female married hisp_eth black white nhres nhres_2yr resspouse livealone adl_dep_core iadl_dep_core adl_sp_helper iadl_sp_helper hh_worker hseduc srh_pf cesd_tot_ge3
local cvars reschil comor_in_hrs age networth_adj2012 
local ivars2 mcare_claims maid_claims maid_hh mcare_hh

local rd: word count `ivars' `cvars' `ivars2' 1

mat tab1=J(`rd', 2, .)
mat stars=J(`rd',2,0)

local r = 1

foreach x of local ivars {


sum `x' if hcall==1
mat tab1[`r',1] = r(mean)*100

sum `x' if hcall==0
mat tab1[`r',2] = r(mean)*100

tab `x' hcall, chi2
mat stars[`r',2] = (r(p)<.01) + (r(p)<0.05)

local ++r

}

foreach x of local cvars {

sum `x' if hcall==1
mat tab1[`r',1] = r(mean)

sum `x' if hcall==0
mat tab1[`r',2] = r(mean)

ttest `x', by(hcall)
mat stars[`r',2] = (r(p)<.01) + (r(p)<0.05)
local ++r
}

foreach x of local ivars2 {

sum `x' if hcall==1
mat tab1[`r',1] = r(mean)*100

sum `x' if hcall==0
mat tab1[`r',2] = r(mean)*100

tab `x' hcall, chi2
mat stars[`r',2] = (r(p)<.01) + (r(p)<0.05)

local ++r

}

sum all if hcall==1
mat tab1[`r',1] = r(N)

sum all if hcall==0
mat tab1[`r',2] = r(N)

mat rownames tab1 = `ivars' `cvars' `ivars2' "Sample Size"

frmttable using "E:\projects\HBMC_HRS\logs\table1.doc", replace statmat(tab1) ///
varlabels title("HRS 1998-2014: HBMC based on CPT/POS codes in Medicare Carrier") ctitles("", "HBMC", "No HBMC") sdec(2) ///
annotate(stars) asymbol(*,**) ///
note("These are unique people, and only survey data from their most recent HRS interview was used. Housecalls are +/- 90 days of ivw date. *p<0.05, **p<0.01")


H="HRS - Data pull"
libname hrs 'E:\data\hrs_cleaned';
libname maid 'E:\data\CMS_DUA_51675_2014\Medicaid_merged';
libname medcare 'E:\data\CMS_DUA_51675_2014\Merged\SAS';

proc import datafile="E:\data\CMS_DUA_51675_2014\Medicaid_merged\MedicaidXref2012_old.dta" out=medicaidxwalk dbms=stata replace; run;

proc import datafile="E:\data\HBMC_HRS\int_data\hrs_incident_dem.dta" out=firstdem dbms=stata replace; run;


proc sql; /* Community dwelling with any dementia  */
create table hrs_firstdem as select a.*, b.first_dem
from hrs.core_00_to_14 a
inner join firstdem b
on a.id=b.id and a.nhres<1;
quit;

proc sql;
create table hrs_firstdem2 as select a.*, b.bid_hrs_23, c.bid_hrs_22
from hrs.core_00_to_14 a
left join medicaidxwalk b
on a.id=b.id
left join medcare.Xref2015medicare c
on a.id=c.hhidpn;
quit;


proc export data=hrs_firstdem2 outfile="E:\data\HBMC_HRS\int_data\hrs_core_dementiaonly.dta" dbms=stata replace; run;

proc sql;
create table hrs_medicaid as select a.*, b.bid_hrs_23
from hrs_firstdem a
inner join medicaidxwalk b
on a.id=b.id;
quit;

data ot_file;
set maid.hrs_max_ot_99_12;
beg_dos = input(put(beginning_date_of_service,8.),YYMMDD8.);
end_dos = input(put(ending_date_of_service,8.),YYMMDD8.);
admit_year = year(beg_dos);
where msis_type_of_service in:(30,51,13,31,33,26,38,54); *home health claims code;
run;

proc freq data=ot_file; tables beginning_date_of_service beg_dos / missprint; run;

proc freq data=ot_file; tables msis_type_of_service / missprint; run;

proc sql;
create table hrs_medicaid_hh as select a.id, a.core_year, a.bid_hrs_23, b.beg_dos, b.end_dos, b.msis_type_of_service, b.admit_year
from hrs_medicaid a
inner join ot_file b
on a.bid_hrs_23=b.bid_hrs_23 and b.admit_year=a.core_year;
quit;

proc freq data=hrs_medicaid_hh; tables msis_type_of_service; run;

data hrs_medicaid_hh;
set hrs_medicaid_hh;
if msis_type_of_service=13 then medicaid_hh = 1;
if msis_type_of_service=26 then medicaid_trn = 1;
if msis_type_of_service=30 then medicaid_pc = 1;
if msis_type_of_service=31 then medicaid_tcm = 1;
if msis_type_of_service=33 then medicaid_reh = 1;
if msis_type_of_service=38 then medicaid_pdn = 1;
if msis_type_of_service ne . then medicaid_hbmc = 1;
run;

proc sql; /* sample size for hh per year */
create table hh_annual as select distinct bid_hrs_23, core_year,
sum(medicaid_hh) as medicaid_hh,
sum(medicaid_trn) as medicaid_trn,
sum(medicaid_pc) as medicaid_pc,
sum(medicaid_tcm) as medicaid_tcm,
sum(medicaid_reh) as medicaid_reh,
sum(medicaid_pdn) as medicaid_pdn,
sum(medicaid_hbmc) as medicaid_hbmc
from hrs_medicaid_hh group by bid_hrs_23, core_year;
quit;

data hh_annual2;
set hh_annual;
array list medicaid_hh--medicaid_hbmc;
do over list;
if list>=1 then list=1;
end;
run;

proc sort data=hh_annual2 nodupkey; by bid_hrs_23 core_year; run;

proc export data=hh_annual2 outfile="E:\data\HBMC_HRS\int_data\medicaid_hh_annual.dta" dbms=stata replace; run; /*annualized medicaid hh */


/* Merge with Medicare crosswalk */

proc sql;
create table hrs_mcare as select a.*, b.bid_hrs_22
from hrs.core_00_to_14 a
inner join medcare.xref2015medicare b
on a.id=b.hhidpn;
quit;

/* Check for cpt and pos codes in carrier file */

* Split carrier file into half due to size;
data carrier_06 (keep = bid_hrs_22 admit_date disch_date admit_year hcpcs_cd PLCRVC01-PLCRVC13);
set medcare.pb_1998_2015;
array dx hcpscd01--hcpscd13;
do over dx;
hcpcs_cd = dx;
output;
end;
where admit_year<=2006;
run;

data carrier_06 (drop = PLCRVC01-PLCRVC13);
set carrier_06;
cptcodes1 = input(compress(hcpcs_cd,'ABCDEFGHIJKLMNOPQRSTUVWXYZ/',),8.);
/*
posflag = 0;
array dx PLCRVC01-PLCRVC13;
do over dx;
if dx in:(12,13,14) then posflag =1;
end;
*/
run;

data carrier_06;
set carrier_06;
cptflag = 0;
if 99341<=cptcodes1<=99350 or 99324<=cptcodes1<=99328 or 99334<=cptcodes1<=99337 then cptflag = 1;
run; 

data carrier_06;
set carrier_06;
where cptflag=1; *or posflag = 1;
run;

proc sort data=carrier_06 nodupkey; by bid_hrs_22 admit_date disch_date; run;

* other half;

data carrier_15 (keep = bid_hrs_22 admit_date disch_date admit_year hcpcs_cd PLCRVC01-PLCRVC13);
set medcare.pb_1998_2015;
array dx hcpscd01--hcpscd13;
do over dx;
hcpcs_cd = dx;
output;
end;
where 2007<=admit_year<=2015;
run;

data carrier_15 (drop = PLCRVC01-PLCRVC13);
set carrier_15;
cptcodes1 = input(compress(hcpcs_cd,'ABCDEFGHIJKLMNOPQRSTUVWXYZ/',),8.);
/*
posflag = 0;
array dx PLCRVC01-PLCRVC13;
do over dx;
if dx in:(12,13,14) then posflag =1;
end;
*/
run;

data carrier_15;
set carrier_15;
cptflag = 0;
if 99341<=cptcodes1<=99350 or 99324<=cptcodes1<=99328 or 99334<=cptcodes1<=99337 then cptflag = 1;
run; 

data carrier_15;
set carrier_15;
where cptflag=1; *or posflag = 1;
run;

proc sort data=carrier_15 nodupkey; by bid_hrs_22 admit_date disch_date; run;

data carrier2;
set carrier_06 carrier_15;
by bid_hrs_22;
if cptflag=1 /*and posflag=1 */ then housecall = 1;
admit_year = year(admit_date);
run;

proc sql;
create table carrier3_dem as select a.*, b.core_year
from carrier2 a
inner join hrs_firstdem2 b
on a.bid_hrs_22=b.bid_hrs_22 and a.admit_year=b.core_year;
quit;


proc sql; /* collapse into single row per person per year */
create table mcare_annual as select distinct bid_hrs_22, core_year,
sum(cptflag) as cpt_flag_n,
/* sum(posflag) as pos_flag, */
sum(housecall) as both_flag_n
from carrier3_dem group by bid_hrs_22, core_year;
quit;

proc sort data=mcare_annual out=mcare_total nodupkey; by bid_hrs_22; run; 

data mcare_annual;
set mcare_annual;
cpt_flag = 0;
both_flag = 0;
if cpt_flag_n>=1 then cpt_flag=1;
/* if pos_flag>=1 then pos_flag=1;*/
if both_flag_n>=1 then both_flag=1;
run;

proc sort data=mcare_annual nodupkey; by bid_hrs_22 core_year; run;

proc export data=mcare_annual outfile="E:\data\HBMC_HRS\int_data\medicare_carrier_annual.dta" dbms=stata replace; run;

/* Medicare home health */

data hrs_hh (keep = bid_hrs_22 claim_id_hrs_22 admit_date disch_date admit_year per_part_b val_cd01-val_cd36  typesrvc);
set medcare.hh_1998_2015;
if typesrvc = "2" then per_part_b = 1;
run;

data hrs_hh (drop = val_cd01-val_cd36);
set hrs_hh;
hh_val_a = 0;
hh_val_b = 0;
array val val_cd01--val_cd36;
do over val;
if val in:("62","64") then hh_val_a = 1;
if val in:("63","65") then hh_val_b = 1;
end;
run;


proc freq data=hrs_hh; tables hh_val_a * admit_year hh_val_b * admit_year; run;

proc sql;
create table hrs_hh2 as select a.*, b.core_year
from hrs_hh a
inner join hrs_firstdem2 b
on a.bid_hrs_22=b.bid_hrs_22 and a.admit_year=b.core_year;
quit;

proc sql; /*unique people per year */
create table hrs_hh_annual as select bid_hrs_22, core_year,
count(admit_year ne .) as num_hh_claim,
count(per_part_b) as per_part_b,
sum(hh_val_a) as hh_val_a,
sum(hh_val_b) as hh_val_b
from hrs_hh2 group by bid_hrs_22, core_year;
quit;

data hrs_hh_annual;
set hrs_hh_annual;
hh_claim = 1;
hh_part_b = 0;
hh_val_p_b = 0;
hh_val_p_a = 0;
if per_part_b>0 then hh_part_b = 1;
if hh_val_b > 0 then hh_val_p_b = 1;
if hh_val_a > 0 then hh_val_p_a = 1;
run;

proc sort data=hrs_hh_annual nodupkey; by bid_hrs_22 core_year; run;

proc export data=hrs_hh_annual outfile="E:\data\HBMC_HRS\int_data\medicare_hh_annual.dta" dbms=stata replace; run;

/* Merge back with HRS dataset */

proc sql;
create table hh_join as select a.*, b.*, c.cpt_flag, c.both_flag, c.cpt_flag_n, c.both_flag_n, d.hh_claim, d.num_hh_claim, d.per_part_b, d.hh_part_b, d.hh_val_b, d.hh_val_p_b, d.hh_val_a, d.hh_val_p_a
from hrs_firstdem2 a 
left join hh_annual2 b
on a.bid_hrs_23=b.bid_hrs_23 and a.core_year=b.core_year
left join mcare_annual c
on a.bid_hrs_22=c.bid_hrs_22 and a.core_year=c.core_year
left join hrs_hh_annual d
on a.bid_hrs_22=d.bid_hrs_22 and a.core_year=d.core_year;
quit;

proc export data=hh_join outfile="E:\data\HBMC_HRS\int_data\hrs_p01.dta" dbms=stata replace; run;

H="HRS - Determining FFS "
/* Stata Code */

use "E:\data\HBMC_HRS\int_data\hrs_p01.dta", replace

cap drop _m
merge 1:1 id core_year using "E:\data\hrs_public_2014\dementia\pdem_withvarnames_00_14.dta", keepus(pdem)


gen dementia = 0
replace dementia = 1 if pdem>=0.5 & pdem!=.

keep id bid_hrs_22 c_ivw_date c_ivw_month c_ivw_year dementia

rename c_ivw_month index_month
rename c_ivw_year index_year
rename c_ivw_date index_date

keep if dementia==1

saveold "E:\data\HBMC_HRS\int_data\index_dates.dta", version(12) replace

/* SAS Code */

libname medi  'E:\data\CMS_DUA_51675_2014\Merged\SAS';
libname proj_int "E:\data\HBMC_HRS\int_data";
 
proc import datafile="E:\data\HBMC_HRS\int_data\index_dates.dta" out=proj_int.index dbms=stata replace; run;

/*sort claims denominator file*/

proc sort data=medi.bqsf_1998_2015 out=dn  nodupkey;
by bid_hrs_22 start_dt;
run;

proc sort data=proj_int.index out=index1 nodupkey;
by bid_hrs_22 index_year;
run;

/*get dn just for interview year*/

proc sql; 
create table dn_index_quarter as select
a.*,b.ab_mo_cnt,b.start_dt,b.end_dt,b.hmo_mo
from index1 a inner join
dn b
on trim(left(a.bid_hrs_22))=trim(left(b.bid_hrs_22)) 
and b.start_dt<=a.index_date<=b.end_dt;
quit;


data all_insurance_0 (rename=(hmo_mo=hmo0 ab_mo_cnt=ab0));
set dn_index_quarter;
ffs0=ab_mo_cnt>=1 & hmo_mo=0;
set dn_index_quarter;
format index_date date9.;
run;

data all_insurance_0b;
set all_insurance_0;
ab_mos0=ab0;
if ffs0=1 then ffs_mos0=ab_mos0;
if ffs0=0 then ffs_mos0=0;
run;


%macro insyrs(numyrs=);
%let y=%eval(&numyrs.*4);
%do i=1 %to &y.;

%let l=%eval(&i.-1);
proc sql; 
create table dn&i. as select
a.*,b.ab_mo_cnt,b.start_dt,b.end_dt,b.hmo_mo
from index1 a inner join
dn b
on trim(left(a.bid_hrs_22))=trim(left(b.bid_hrs_22)) 
and b.start_dt<=a.index_date-(&i.*(365.25/4))<=end_dt;
quit;

data all_insurance_&i.(rename=(hmo_mo=hmo&i. ab_mo_cnt=ab&i.)); 
set dn&i.;
ffs&i.=ab_mo_cnt>=1 & hmo_mo=0;
format index_date date9.;
run;

proc sql;
create table all_insurance_&i.2 as select * from
all_insurance_&l.b a
left join
all_insurance_&i. b
on a.bid_hrs_22=b.bid_hrs_22;
quit;

data all_insurance_&i.b (drop=ab_mos&l. ffs_mos&l.);
set all_insurance_&i.2;
ab_mos&i.=ab_mos&l.+ab&i.;
if ffs&i.=. then ffs&i.=0;
if ffs&l.=0 then ffs&i.=0;
if ffs&i.=1 then ffs_mos&i.=ab&i.+ffs_mos&l.;
if ffs&i.=0 then ffs_mos&i.=ffs_mos&l.;
run;

%end;

data all_insurance;
set all_insurance_&y.b;
cont_ffs_n_mos=ffs_mos&y.;
run;
%mend;




%insyrs(numyrs=1);


data proj_int.ffs_before;
set all_insurance;
run;

proc export data=proj_int.ffs_before outfile="E:\data\HBMC_HRS\int_data\ffs_before.dta" replace; run;

H="HRS - P01 Longitudinal Table"
use "E:\data\HBMC_HRS\int_data\hrs_p01.dta", replace

cap drop _m
merge 1:1 id core_year using "E:\data\hrs_public_2014\dementia\pdem_withvarnames_00_14.dta", keepus(pdem)

gen dementia = 0
replace dementia = 1 if pdem>=0.5 & pdem!=.

replace both_flag = 0
replace hh_claim = 0 if hh_claim==.
replace num_hh_claim = 0 if num_hh_claim==.
replace per_part_b = 0 if per_part_b==.
replace hh_part_b = 0 if hh_part_b==.
replace both_flag = 1 if cpt_flag==1 
label var both_flag "HBMC based on CPT codes"


* HH values codes are flaky for 1998-2000
replace per_part_b = hh_val_b if core_year>2000
replace hh_part_b = hh_val_p_b if core_year>2000

drop _m

local logpath "E:\data\HBMC_HRS\logs"
local date=subinstr("$S_DATE"," ","_",.)

gen all = 1

gen index_date = c_ivw_date

drop if c_ivw_date==.
merge 1:1 id index_date using "E:\data\HBMC_HRS\int_data\ffs_before.dta", keepus(cont_ffs_n_mos)
drop _m

gen has_medicaid =0
replace has_medicaid = 1 if bid_hrs_23!=""
label var has_medicaid "Has Medicaid Claims"

gen dem_maid = 0
replace dem_maid = 1 if dementia==1 & has_medicaid==1
label var dem_maid "Has Dementia & Medicaid"

gen ffs_6m = 0
replace ffs_6m = 1 if cont_ffs_n_mos>=6 & cont_ffs_n_mos!=.
label var ffs_6m "Has >=6m of Medicare FFS prior to ivw"

gen has_medicare = 0
replace has_medicare = 1 if bid_hrs_22!=""
label var has_medicare "Has Medicare Claims"

local needem medicaid_hh medicaid_trn medicaid_pc medicaid_tcm medicaid_reh medicaid_pdn medicaid_hbmc

foreach x of local needem { /* restricting columns to dementia + mediciad */
replace `x' = 0 if dem_maid==0
}

gen dem_ffs = 0
replace dem_ffs = 1 if dementia==1 & ffs_6m==1


local cvars all dementia dem_maid medicaid_hh medicaid_trn medicaid_pc medicaid_tcm medicaid_reh medicaid_pdn medicaid_hbmc // hh_part_b both_flag
local full: word count `cvars'
mat tab1=J(9,`full',.)
local r = 1
local c = 1

preserve
keep if nhres==0

forvalues i=1998(2)2014 {

	foreach x of local cvars {
	
sum `x' if core_year==`i'
mat tab1[`r',`c'] = r(sum)

local ++c
}

local c = 1
local ++r
}

mat rownames tab1 = "1998" "2000" "2002" "2004" "2006" "2008" "2010" "2012" "2014" 

frmttable using `logpath'\HRS_P01_longitudinal_`date'.doc, replace statmat(tab1) ///
varlabels title("HRS 1998-2014 with Community Dwelling + Dementia: Medicaid HBCS Breakdown") ctitles("Year", "Full Sample", "Dementia (N)", "Dementia + Medicaid", "Medicaid HH" "Transport" "Personal Care" "Targeted Case Mang." "Rehab Services" "Priv. Duty Nurse" "Any HBCS") sdec(0) ///
note("Medicaid HCBS Utilization restricted to people with Dementia") 

foreach x of varlist medicaid_hbmc hh_part_b both_flag {
replace `x' = 0 if dem_ffs==0
}


local cvars all dementia dem_ffs medicaid_hbmc hh_part_b both_flag
local full: word count `cvars'
mat tab1=J(9,`full',.)
local r = 1
local c = 1

forvalues i=1998(2)2014 {

	foreach x of local cvars {
	
sum `x' if core_year==`i'
mat tab1[`r',`c'] = r(sum)

local ++c
}

local c = 1
local ++r
}

mat rownames tab1 = "1998" "2000" "2002" "2004" "2006" "2008" "2010" "2012" "2014" 

frmttable using `logpath'\HRS_P01_longitudinal_`date'.doc, addtable statmat(tab1) ///
varlabels title("HRS 1998-2014 with Community Dwelling + Dementia: Prevalence Sample Size") ctitles("Year", "Full Sample", "Dementia (N)", "Dementia + 6m FFS", "Any Medicaid HCBS" "Medicare HH" "Medicare HBMC" ) sdec(0) ///
note("Medicare/Medicaid Utilization restricted to people with Dementia & 6m Medicare FFS prior to ivw")

restore

/* Identifying Incident Dementia + Community Dwelling */

cap drop _m

merge m:1 id using "E:\data\hrs_cleaned\death_date_2014.dta", keepus(death_year death_all)
drop if _m==2
drop _m

gen year = core_year
merge 1:1 id year using "E:\data\hrs_cleaned\helper_hours_2016.dta", keepus(n_i n_f)
drop if _m==2
drop _m


preserve
keep if dementia==1 & nhres==0
gsort id core_year
by id: gen firstdem = 1 if _n==1 // incident dementia
keep if firstdem==1
rename core_year incident_year
tempfile firstdem
save `firstdem'
restore

preserve
keep if both_flag==1
keep id
duplicates drop
gen any_mc_hbmc = 1
tempfile any
save `any'
restore

preserve
keep if medicaid_hbmc==1
keep id 
duplicates drop
gen any_md_hbmc = 1
tempfile any2
save `any2'
restore


merge m:1 id using "`firstdem'", keepus(incident_year)
drop _m
drop if core_year<incident_year
merge m:1 id using "`any'", keepus(any_mc_hbmc)
drop if _m==2
drop _m

merge m:1 id using "`any2'", keepus(any_md_hbmc)
drop if _m==2
drop _m

gsort id core_year
by id: gen dwave = _n

gen informal = 0
replace informal = 1 if n_i>0 & n_i!=.
label var informal "Any unpaid helpers"

gen formal = 0
replace formal = 1 if n_f>0 & n_f!=.
label var formal "Any paid helpers"

gen anyhelp = 0
replace anyhelp = 1 if formal==1 | informal==1
label var anyhelp "Any Paid/Unpaid Helpers"

gen nohelp = 0
replace nohelp = 1 if anyhelp==0
label var nohelp "No Helpers" 

label var both_flag "Medicare HBMC in calendar year"
label var any_mc_hbmc "Any Medicare HBMC 1998-2015"
label var any_md_hbmc "Any Medicaid HH/HCBS 1999-2012"
label var medicaid_hbmc "Medicaid HH/HCBS in calendar year"

gen any_hbmc = 0
replace any_hbmc = 1 if any_mc_hbmc==1 | any_md_hbmc==1
label var any_hbmc "Any Medicare HBMC or Medicaid HH/HCBS 1998-2015"

label var all "# at Risk (Unqiue People)"
label var hh_part_b "Medicare HH claim Part B in calendar year"
label var medicaid_hh "Medicaid HH claim in calendar year"
gsort id -core_year

by id: gen death_sy = 1 if death_year==core_year
label var death_sy "Died after ivw in the same calendar year"
by id: gen death_ny = 1 if (death_year>core_year & _n==1 & death_year!=.)
label var death_ny "Last observed ivw, dies year(s) after ivw"

gsort id core_year
by id: gen obs=_n
by id: gen ltf = 1 if obs==_n & obs[_n+1]==.



local ivars death_sy death_ny nhres informal formal anyhelp nohelp both_flag hh_part_b medicaid_hh has_medicare has_medicaid medicaid_hbmc any_mc_hbmc any_md_hbmc any_hbmc all

local full: word count `ivars'
mat tab1=J(`full',9,.)
local r=1
local c=1

foreach x of local ivars {
	forvalues i=1/9 {
	sum `x' if dwave==`i'
	mat tab1[`r',`c']=r(sum)
	local ++c
	}
	
	local c = 1
	local ++r
	}
	
mat rownames tab1 = `ivars'

frmttable using `logpath'\HRS_P01_longitudinal_`date'.doc, addtable statmat(tab1) ///
varlabels title("HRS 1998-2014 with Community Dwelling + Dementia: Following People from Incident Dementia") ctitles("Variables", "Year 1", "Year 3", "Year 5", "Year 7", "Year 9", "Year 11", "Year 13", "Year 15", "Year 17") sdec(0) ///
note("Each Year represents a HRS core interview, which occurs every 2 years. Sample is pulled from HRS 1998-2014 core interviews.")


local ivars death_sy death_ny nhres informal formal anyhelp nohelp both_flag hh_part_b medicaid_hh has_medicare has_medicaid medicaid_hbmc any_mc_hbmc any_md_hbmc any_hbmc all

gen keepvar = 0

levelsof id if dwave==1 & ffs_6m==1, local(index) 

foreach x of local index {

replace keepvar = 1 if id=="`x'"

}

keep if keepvar==1






local full: word count `ivars'
mat tab1=J(`full',9,.)
local r=1
local c=1

foreach x of local ivars {
	forvalues i=1/9 {
	sum `x' if dwave==`i'
	mat tab1[`r',`c']=r(sum)
	local ++c
	}
	
	local c = 1
	local ++r
	}
	
mat rownames tab1 = `ivars'

frmttable using `logpath'\HRS_P01_longitudinal_`date'.doc, addtable statmat(tab1) ///
varlabels title("HRS 1998-2014 with Community Dwelling + Dementia + 6m FFS at Incident: Following People from Incident Dementia") ctitles("Variables", "Year 1", "Year 3", "Year 5", "Year 7", "Year 9", "Year 11", "Year 13", "Year 15", "Year 17") sdec(0) ///
note("Each Year represents a HRS core interview, which occurs every 2 years. Sample is pulled from HRS 1998-2014 core interviews.")





replace both_flag = 0 if nhres==1
replace hh_part_b = 0 if nhres==1 | both_flag==1
replace anyhelp = 0 if nhres==1 | both_flag==1 | hh_part_b==1

gen no_support = 1
replace no_support = 0 if nhres==1 | both_flag==1 | hh_part_b==1 | anyhelp==1 

gen death = 0
replace death = 1 if death_sy==1 | death_ny==1

label var ltf "Loss to follow-up"

local ivars nhres both_flag hh_part_b anyhelp no_support all 
local ivars2 death

local full: word count `ivars' `ivars2'
mat tab1=J(`full',9,.)
local r=1
local c=1

foreach x of local ivars {
	forvalues i=1/9 {
	sum `x' if dwave==`i'
	mat tab1[`r',`c']=r(sum)
	local ++c
	}
	
	local c = 1
	local ++r
	}

	
	local c = 2

forvalues i = 2/9 {
	
sum death if dwave==`i'
mat tab1[`r',`c'] = r(sum)

local ++c
}



mat rownames tab1 = `ivars' `ivars2'

frmttable using `logpath'\HRS_P01_longitudinal_`date'.doc, addtable statmat(tab1) ///
varlabels title("HRS 1998-2014 with Community Dwelling + Dementia + 6m FFS at Incident: Following People from Incident Dementia") ctitles("Variables", "Year 1", "Year 3", "Year 5", "Year 7", "Year 9", "Year 11", "Year 13", "Year 15", "Year 17") sdec(0) ///
note("Each Year represents a HRS core interview, which occurs every 2 years. Missing Interviews are not counted as loss to followup.")




H="HRS - Sample Size Table"

/******* HRS Community Dwelling + Dementia *****************/

use "E:\data\HBMC_HRS\int_data\hrs_p01.dta", replace

cap drop _m
merge 1:1 id core_year using "E:\data\hrs_public_2014\dementia\pdem_withvarnames_00_14.dta", keepus(pdem)
keep if nhres==0
cap drop _m

preserve
gsort id core_year

by id: gen first_year = core_year if _n==1
keep id first_year
drop if first_year==.

save "E:\data\HBMC_HRS\int_data\firstcore.dta", replace
restore



replace per_part_b = hh_val_b if core_year>2000
replace hh_part_b = hh_val_p_b if core_year>2000

gen dementia = 0
replace dementia = 1 if pdem>=0.5 & pdem!=.

replace both_flag = 0
replace hh_claim = 0 if hh_claim==.
replace num_hh_claim = 0 if num_hh_claim==.
replace per_part_b = 0 if per_part_b==.
replace hh_part_b = 0 if hh_part_b==.
replace both_flag = 1 if cpt_flag==1 

local logpath "E:\data\HBMC_HRS\logs"
local date=subinstr("$S_DATE"," ","_",.)

gen all = 1

gen index_date = c_ivw_date

drop if c_ivw_date==.
merge 1:1 id index_date using "E:\data\HBMC_HRS\int_data\ffs_before.dta", keepus(cont_ffs_n_mos)
drop _m

gen both_hbmc = 0
replace both_hbmc = 1 if both_flag==1


gen hbmc_hh = 0
replace hbmc_hh = 1 if both_hbmc==1 & hh_claim==1

gen hbmc_nohh = 0
replace hbmc_nohh = 1 if both_hbmc==1 & hh_claim==0


gen ffs_6m = 0
replace ffs_6m = 1 if cont_ffs_n_mos>=6 & cont_ffs_n_mos!=.
label var ffs_6m "Has >=6m of Medicare FFS prior to ivw"

gen has_medicare = 0
replace has_medicare = 1 if bid_hrs_22!=""
label var has_medicare "Has Medicare Claims"

gen hbmc_n = 0
replace hbmc_n = 1 if cpt_flag_n>1 & cpt_flag_n!=.
label var hbmc_n "Indicator of multiple Medicare HBMC in calendar year"


gen dem_ffs = 0
replace dem_ffs = 1 if dementia==1 & ffs_6m==1

/*
foreach x of varlist hh_claim both_hbmc hh_claim hh_part_b hbmc_hh hbmc_nohh num_hh_claim num_hh_claim per_part_b {
replace `x' = 0 if dem_ffs==0
}

*/

foreach x of varlist hh_claim both_hbmc hbmc_n cpt_flag_n hh_claim hh_part_b hbmc_hh hbmc_nohh num_hh_claim num_hh_claim per_part_b {
replace `x' = 0 if dementia!=1
}



local cvars all dementia dem_ffs both_hbmc hbmc_n cpt_flag_n hh_claim hh_part_b hbmc_hh hbmc_nohh num_hh_claim num_hh_claim per_part_b
local full: word count `cvars'
mat tab1=J(10,`full',.)
local r = 1
local c = 1

forvalues i=1998(2)2014 {

	foreach x of local cvars {
	
sum `x' if core_year==`i'
mat tab1[`r',`c'] = r(sum)

local ++c
}

local c = 1
local ++r
}
preserve

collapse (sum) num_hh_claim per_part_b cpt_flag_n, by(id)
tempfile coll
save `coll'
restore

collapse (max) all dementia dem_ffs both_hbmc hbmc_n hh_claim hh_part_b hbmc_hh hbmc_nohh, by(id)
merge 1:1 id using `coll'

local c = 1
foreach x of local cvars {
	
sum `x' 
mat tab1[`r',`c'] = r(sum)

local ++c
}

forvalues i = 1/10 {
mat tab1[`i',6] = tab1[`i',6]/tab1[`i',4]
mat tab1[`i',12] = tab1[`i',12]/tab1[`i',7]
mat tab1[`i',13] = ((tab1[`i',13]/tab1[`i',11])*100)
}



mat rownames tab1 = "1998" "2000" "2002" "2004" "2006" "2008" "2010" "2012" "2014" "Unqiue People"

frmttable using `logpath'\HRS_P01_SampleSize_`date'.doc, replace statmat(tab1) ///
varlabels title("HRS 1998-2014 with Community Dwelling + Dementia: Prevalence Sample Size") ///
ctitles("Year", "Full Sample", "Dementia (N)", "Dementia + 6m FFS", "Medicare HBMC", "Multiple Claims HBMC in Calendar Year", "Ave. # of Claims HBMC in Calendar Year", "Medicare HH", "Medicare HH Part B", "HBMC + HH" "HBMC, no HH", "Total # of HHA episodes", "Ave. # of HHA episodes", "% of HHA episodes Part B") sdec(0,0,0,0,0,2,0,0,0,0,0,2,2) ///
note("Restricted to Community Dwelling + Dementia at every wave. No FFS restriction. Ave # of HHA episodes is conditional on having a HHA episode. Ave # of HBMC Claims is conditional on having a HBMC claim. ")

/******* HRS Community Dwelling + Dementia :::: UNIQUE HBMC ***********/

use "E:\data\HBMC_HRS\int_data\hrs_p01.dta", replace

cap drop _m
merge 1:1 id core_year using "E:\data\hrs_public_2014\dementia\pdem_withvarnames_00_14.dta", keepus(pdem)
keep if nhres==0
cap drop _m
merge m:1 id using "E:\data\HBMC_HRS\int_data\firstcore.dta"

replace per_part_b = hh_val_b if core_year>2000
replace hh_part_b = hh_val_p_b if core_year>2000

gen dementia = 0
replace dementia = 1 if pdem>=0.5 & pdem!=.

replace both_flag = 0
replace hh_claim = 0 if hh_claim==.
replace num_hh_claim = 0 if num_hh_claim==.
replace per_part_b = 0 if per_part_b==.
replace hh_part_b = 0 if hh_part_b==.
replace both_flag = 1 if cpt_flag==1 

drop _m

local logpath "E:\data\HBMC_HRS\logs"
local date=subinstr("$S_DATE"," ","_",.)

gen all = 1

gen index_date = c_ivw_date

drop if c_ivw_date==.
merge 1:1 id index_date using "E:\data\HBMC_HRS\int_data\ffs_before.dta", keepus(cont_ffs_n_mos)
drop _m

gen both_hbmc = 0
replace both_hbmc = 1 if both_flag==1


gen hbmc_hh = 0
replace hbmc_hh = 1 if both_hbmc==1 & hh_claim==1

gen hbmc_nohh = 0
replace hbmc_nohh = 1 if both_hbmc==1 & hh_claim==0


gen ffs_6m = 0
replace ffs_6m = 1 if cont_ffs_n_mos>=6 & cont_ffs_n_mos!=.
label var ffs_6m "Has >=6m of Medicare FFS prior to ivw"

gen has_medicare = 0
replace has_medicare = 1 if bid_hrs_22!=""
label var has_medicare "Has Medicare Claims"


gen dem_ffs = 0
replace dem_ffs = 1 if dementia==1 & ffs_6m==1

/*
foreach x of varlist hh_claim both_hbmc hh_claim hh_part_b hbmc_hh hbmc_nohh num_hh_claim num_hh_claim per_part_b {
replace `x' = 0 if dem_ffs==0
}

*/

foreach x of varlist hh_claim both_hbmc hh_claim hh_part_b hbmc_hh hbmc_nohh num_hh_claim num_hh_claim per_part_b {
replace `x' = 0 if dementia!=1
}


forvalues i=1998(2)2014 {

gen hbmc_`i' = 0
replace hbmc_`i' = 1 if both_hbmc==1 & core_year==`i'

levelsof id if hbmc_`i'==1, local(hb)

foreach y of local hb {

drop if id=="`y'" & core_year>`i'

}
}


gen py = 1
replace py = py+(core_year-first_year) if core_year!=first_year



local full: word count both_hbmc 1 1 1 
di "`full'"
mat tab1=J(10,`full',.)
local r = 1
local c = 1


forvalues i=1998(2)2014 {

	
sum both_hbmc if core_year==`i'
mat tab1[`r',1] = r(sum)


local p = `r'-2
local q = `r'-1

if `r'>=3 mat tab1[`r',2] = (tab1[`p',1] + tab1[`q',1] +  tab1[`r',1])/3


local ++r

}

sum all if both_hbmc==1
mat tab1[10,1] = r(sum)

local r = 1
forvalues i = 1998(2)2014 {

sum py if both_hbmc==1 & core_year==`i'
mat tab1[`r',3] = r(sum)
mat tab1[`r',4] = (tab1[`r',3]/tab1[`r',1])

local ++r
}

sum py if both_hbmc==1
mat tab1[10,3] = r(sum)
mat tab1[10,4] = (tab1[`r',3]/tab1[`r',1])



mat rownames tab1 = "1998" "2000" "2002" "2004" "2006" "2008" "2010" "2012" "2014" "Cumulative"

frmttable using `logpath'\HRS_P01_SampleSize_`date'.doc, addtable statmat(tab1) ///
varlabels title("HRS 1998-2014 with Community Dwelling + Dementia: Unique HBMC per wave") ///
ctitles("Year", "Medicare HBMC", "3-Wave Moving Average HBMC", "Follow Time from Enrollment (Person Years)", "Average Follow Time from Enrollment (Person Years)") sdec(0,1,0,2) ///
note("Restricted to Community Dwelling + Dementia at every wave. No FFS restriction.")


/************ HRS Community Dwelling + Dementia + 6m FFS *************/


use "E:\data\HBMC_HRS\int_data\hrs_p01.dta", replace

cap drop _m
merge 1:1 id core_year using "E:\data\hrs_public_2014\dementia\pdem_withvarnames_00_14.dta", keepus(pdem)
keep if nhres==0

replace per_part_b = hh_val_b if core_year>2000
replace hh_part_b = hh_val_p_b if core_year>2000

gen dementia = 0
replace dementia = 1 if pdem>=0.5 & pdem!=.

replace both_flag = 0
replace hh_claim = 0 if hh_claim==.
replace num_hh_claim = 0 if num_hh_claim==.
replace per_part_b = 0 if per_part_b==.
replace hh_part_b = 0 if hh_part_b==.
replace both_flag = 1 if cpt_flag==1 

drop _m

local logpath "E:\data\HBMC_HRS\logs"
local date=subinstr("$S_DATE"," ","_",.)

gen all = 1

gen index_date = c_ivw_date

drop if c_ivw_date==.
merge 1:1 id index_date using "E:\data\HBMC_HRS\int_data\ffs_before.dta", keepus(cont_ffs_n_mos)
drop _m

gen both_hbmc = 0
replace both_hbmc = 1 if both_flag==1


gen hbmc_hh = 0
replace hbmc_hh = 1 if both_hbmc==1 & hh_claim==1

gen hbmc_nohh = 0
replace hbmc_nohh = 1 if both_hbmc==1 & hh_claim==0


gen ffs_6m = 0
replace ffs_6m = 1 if cont_ffs_n_mos>=6 & cont_ffs_n_mos!=.
label var ffs_6m "Has >=6m of Medicare FFS prior to ivw"

gen has_medicare = 0
replace has_medicare = 1 if bid_hrs_22!=""
label var has_medicare "Has Medicare Claims"

gen hbmc_n = 0
replace hbmc_n = 1 if cpt_flag_n>1 & cpt_flag_n!=.
label var hbmc_n "Indicator of multiple Medicare HBMC in calendar year"

gen dem_ffs = 0
replace dem_ffs = 1 if dementia==1 & ffs_6m==1


foreach x of varlist hh_claim both_hbmc hbmc_n cpt_flag_n hh_claim hh_part_b hbmc_hh hbmc_nohh num_hh_claim num_hh_claim per_part_b {
replace `x' = 0 if dem_ffs==0
}


local cvars all dementia dem_ffs both_hbmc hbmc_n cpt_flag_n hh_claim hh_part_b hbmc_hh hbmc_nohh num_hh_claim num_hh_claim per_part_b
local full: word count `cvars'
mat tab1=J(10,`full',.)
local r = 1
local c = 1

forvalues i=1998(2)2014 {

	foreach x of local cvars {
	
sum `x' if core_year==`i'
mat tab1[`r',`c'] = r(sum)

local ++c
}

local c = 1
local ++r
}
preserve

collapse (sum) num_hh_claim per_part_b cpt_flag_n, by(id)
tempfile coll
save `coll'
restore

collapse (max) all dementia dem_ffs both_hbmc hbmc_n hh_claim hh_part_b hbmc_hh hbmc_nohh, by(id)
merge 1:1 id using `coll'

local c = 1
foreach x of local cvars {
	
sum `x' 
mat tab1[`r',`c'] = r(sum)

local ++c
}

forvalues i = 1/10 {
mat tab1[`i',6] = tab1[`i',6]/tab1[`i',4]
mat tab1[`i',12] = tab1[`i',12]/tab1[`i',7]
mat tab1[`i',13] = ((tab1[`i',13]/tab1[`i',11])*100)
}



mat rownames tab1 = "1998" "2000" "2002" "2004" "2006" "2008" "2010" "2012" "2014" "Unqiue People"

frmttable using `logpath'\HRS_P01_SampleSize_`date'.doc, addtable statmat(tab1) ///
varlabels title("HRS 1998-2014 with Community Dwelling + Dementia + 6m FFS: Prevalence Sample Size") ///
ctitles("Year", "Full Sample", "Dementia (N)", "Dementia + 6m FFS", "Medicare HBMC", "Multiple Claims HBMC in Calendar Year", "Ave. # of Claims HBMC in Calendar Year", "Medicare HH", "Medicare HH Part B", "HBMC + HH" "HBMC, no HH", "Total # of HHA episodes", "Ave. # of HHA episodes", "% of HHA episodes Part B") sdec(0,0,0,0,0,2,0,0,0,0,0,2,2) ///
note("Restricted to Community Dwelling + Dementia + 6m FFS at every wave. Ave # of HHA episodes is conditional on having a HHA episode. Ave # of HBMC Claims is conditional on having a HBMC claim. ")
 
/******* HRS Community Dwelling + Dementia :::: UNIQUE HBMC ***********/

use "E:\data\HBMC_HRS\int_data\hrs_p01.dta", replace

cap drop _m
merge 1:1 id core_year using "E:\data\hrs_public_2014\dementia\pdem_withvarnames_00_14.dta", keepus(pdem)
keep if nhres==0
drop _m
merge m:1 id using "E:\data\HBMC_HRS\int_data\firstcore.dta"

replace per_part_b = hh_val_b if core_year>2000
replace hh_part_b = hh_val_p_b if core_year>2000

gen dementia = 0
replace dementia = 1 if pdem>=0.5 & pdem!=.

replace both_flag = 0
replace hh_claim = 0 if hh_claim==.
replace num_hh_claim = 0 if num_hh_claim==.
replace per_part_b = 0 if per_part_b==.
replace hh_part_b = 0 if hh_part_b==.
replace both_flag = 1 if cpt_flag==1 

drop _m

local logpath "E:\data\HBMC_HRS\logs"
local date=subinstr("$S_DATE"," ","_",.)

gen all = 1

gen index_date = c_ivw_date

drop if c_ivw_date==.
merge 1:1 id index_date using "E:\data\HBMC_HRS\int_data\ffs_before.dta", keepus(cont_ffs_n_mos)
drop _m

gen both_hbmc = 0
replace both_hbmc = 1 if both_flag==1


gen hbmc_hh = 0
replace hbmc_hh = 1 if both_hbmc==1 & hh_claim==1

gen hbmc_nohh = 0
replace hbmc_nohh = 1 if both_hbmc==1 & hh_claim==0


gen ffs_6m = 0
replace ffs_6m = 1 if cont_ffs_n_mos>=6 & cont_ffs_n_mos!=.
label var ffs_6m "Has >=6m of Medicare FFS prior to ivw"

gen has_medicare = 0
replace has_medicare = 1 if bid_hrs_22!=""
label var has_medicare "Has Medicare Claims"


gen dem_ffs = 0
replace dem_ffs = 1 if dementia==1 & ffs_6m==1


foreach x of varlist hh_claim both_hbmc hh_claim hh_part_b hbmc_hh hbmc_nohh num_hh_claim num_hh_claim per_part_b {
replace `x' = 0 if dem_ffs==0
}



forvalues i=1998(2)2014 {

gen hbmc_`i' = 0
replace hbmc_`i' = 1 if both_hbmc==1 & core_year==`i'

levelsof id if hbmc_`i'==1, local(hb)

foreach y of local hb {

drop if id=="`y'" & core_year>`i'

}
}


gen py = 1
replace py = py+(core_year-first_year) if core_year!=first_year



local full: word count both_hbmc 1 1 1 
di "`full'"
mat tab1=J(10,`full',.)
local r = 1
local c = 1


forvalues i=1998(2)2014 {

	
sum both_hbmc if core_year==`i'
mat tab1[`r',1] = r(sum)


local p = `r'-2
local q = `r'-1

if `r'>=3 mat tab1[`r',2] = (tab1[`p',1] + tab1[`q',1] +  tab1[`r',1])/3


local ++r

}

sum all if both_hbmc==1
mat tab1[10,1] = r(sum)

local r = 1
forvalues i = 1998(2)2014 {

sum py if both_hbmc==1 & core_year==`i'
mat tab1[`r',3] = r(sum)
mat tab1[`r',4] = (tab1[`r',3]/tab1[`r',1])

local ++r
}

sum py if both_hbmc==1
mat tab1[10,3] = r(sum)
mat tab1[10,4] = (tab1[`r',3]/tab1[`r',1])



mat rownames tab1 = "1998" "2000" "2002" "2004" "2006" "2008" "2010" "2012" "2014" "Cumulative"

frmttable using `logpath'\HRS_P01_SampleSize_`date'.doc, addtable statmat(tab1) ///
varlabels title("HRS 1998-2014 with Community Dwelling + Dementia + 6m FFS: Unique HBMC per wave") ///
ctitles("Year", "Medicare HBMC", "3-Wave Moving Average HBMC", "Follow Time from Enrollment (Person Years)", "Average Follow Time from Enrollment (Person Years)") sdec(0,1,0,2) ///
note("Restricted to Community Dwelling + Dementia + 6m FFS at every wave.")



H="HRS - Sample Comparison"

/******* HRS Community Dwelling + Dementia *****************/

use "E:\data\HBMC_HRS\int_data\hrs_p01.dta", replace

cap drop _m
merge 1:1 id core_year using "E:\data\hrs_public_2014\dementia\pdem_withvarnames_00_14.dta", keepus(pdem)
keep if nhres==0
cap drop _m

preserve
gsort id core_year

by id: gen first_year = core_year if _n==1
keep id first_year
drop if first_year==.

save "E:\data\HBMC_HRS\int_data\firstcore.dta", replace
restore

replace per_part_b = hh_val_b if core_year>2000
replace hh_part_b = hh_val_p_b if core_year>2000

gen dementia = 0
replace dementia = 1 if pdem>=0.5 & pdem!=.

replace both_flag = 0
replace hh_claim = 0 if hh_claim==.
replace num_hh_claim = 0 if num_hh_claim==.
replace per_part_b = 0 if per_part_b==.
replace hh_part_b = 0 if hh_part_b==.
replace both_flag = 1 if cpt_flag==1 

local logpath "E:\data\HBMC_HRS\logs"
local date=subinstr("$S_DATE"," ","_",.)

gen all = 1

gen index_date = c_ivw_date

drop if c_ivw_date==.
merge 1:1 id index_date using "E:\data\HBMC_HRS\int_data\ffs_before.dta", keepus(cont_ffs_n_mos)
drop _m

gen both_hbmc = 0
replace both_hbmc = 1 if both_flag==1


gen hbmc_hh = 0
replace hbmc_hh = 1 if both_hbmc==1 & hh_claim==1

gen hbmc_nohh = 0
replace hbmc_nohh = 1 if both_hbmc==1 & hh_claim==0


gen ffs_6m = 0
replace ffs_6m = 1 if cont_ffs_n_mos>=6 & cont_ffs_n_mos!=.
label var ffs_6m "Has >=6m of Medicare FFS prior to ivw"

gen has_medicare = 0
replace has_medicare = 1 if bid_hrs_22!=""
label var has_medicare "Has Medicare Claims"

gen hbmc_n = 0
replace hbmc_n = 1 if cpt_flag_n>1 & cpt_flag_n!=.
label var hbmc_n "Indicator of multiple Medicare HBMC in calendar year"


gen dem_ffs = 0
replace dem_ffs = 1 if dementia==1 & ffs_6m==1

preserve
keep if dementia==1 & nhres==0
gsort id core_year
by id: gen firstdem = 1 if _n==1 // incident dementia
keep if firstdem==1
rename core_year incident_year
tempfile firstdem
save `firstdem'
restore

preserve
keep if both_flag==1
keep id
duplicates drop
gen any_mc_hbmc = 1
tempfile any
save `any'
restore

preserve
keep if medicaid_hbmc==1
keep id 
duplicates drop
gen any_md_hbmc = 1
tempfile any2
save `any2'
restore


merge m:1 id using "`firstdem'", keepus(incident_year firstdem)

gen firstdemhbmc = 0
replace firstdemhbmc = 1 if firstdem==1 & both_hbmc==1


foreach x of varlist hh_claim both_hbmc hbmc_n cpt_flag_n hh_claim hh_part_b hbmc_hh hbmc_nohh num_hh_claim num_hh_claim per_part_b {
replace `x' = 0 if dem_ffs==0
}



local cvars all dementia dem_ffs both_hbmc
local full: word count `cvars'
mat tab1=J(10,`full',.)
local r = 1
local c = 1

forvalues i=1998(2)2014 {

	foreach x of local cvars {
	
sum `x' if core_year==`i'
mat tab1[`r',`c'] = r(sum)

local ++c
}

local c = 1
local ++r
}
preserve

collapse (sum) num_hh_claim per_part_b cpt_flag_n, by(id)
tempfile coll
save `coll'
restore

collapse (max) all dementia dem_ffs both_hbmc hbmc_n hh_claim hh_part_b hbmc_hh hbmc_nohh, by(id)
merge 1:1 id using `coll'

local c = 1
foreach x of local cvars {
	
sum `x' 
mat tab1[`r',`c'] = r(sum)

local ++c
}


mat rownames tab1 = "1998" "2000" "2002" "2004" "2006" "2008" "2010" "2012" "2014" "Unqiue People"

frmttable using `logpath'\HRS_P01_SampleDifferences_`date'.doc, replace statmat(tab1) ///
varlabels title("HRS 1998-2014 with Community Dwelling + Dementia: Prevalence Sample Size") ///
ctitles("Year", "Full Sample", "Dementia (N)", "Dementia + 6m FFS", "Medicare HBMC") sdec(0) ///
note("Restricted to Community Dwelling + Dementia at every wave. ")




/* Identifying Incident Dementia + Community Dwelling */

cap drop _m

merge m:1 id using "E:\data\hrs_cleaned\death_date_2014.dta", keepus(death_year death_all)
drop if _m==2
drop _m

gen year = core_year
merge 1:1 id year using "E:\data\hrs_cleaned\helper_hours_2016.dta", keepus(n_i n_f)
drop if _m==2
drop _m


preserve
keep if dementia==1 & nhres==0
gsort id core_year
by id: gen firstdem = 1 if _n==1 // incident dementia
keep if firstdem==1
rename core_year incident_year
tempfile firstdem
save `firstdem'
restore

preserve
keep if both_flag==1
keep id
duplicates drop
gen any_mc_hbmc = 1
tempfile any
save `any'
restore

preserve
keep if medicaid_hbmc==1
keep id 
duplicates drop
gen any_md_hbmc = 1
tempfile any2
save `any2'
restore


merge m:1 id using "`firstdem'", keepus(incident_year)
drop _m
drop if core_year<incident_year
merge m:1 id using "`any'", keepus(any_mc_hbmc)
drop if _m==2
drop _m

merge m:1 id using "`any2'", keepus(any_md_hbmc)
drop if _m==2
drop _m

gsort id core_year
by id: gen dwave = _n

gen informal = 0
replace informal = 1 if n_i>0 & n_i!=.
label var informal "Any unpaid helpers"

gen formal = 0
replace formal = 1 if n_f>0 & n_f!=.
label var formal "Any paid helpers"

gen anyhelp = 0
replace anyhelp = 1 if formal==1 | informal==1
label var anyhelp "Any Paid/Unpaid Helpers"

gen nohelp = 0
replace nohelp = 1 if anyhelp==0
label var nohelp "No Helpers" 

label var both_flag "Medicare HBMC in calendar year"
label var any_mc_hbmc "Any Medicare HBMC 1998-2015"
label var any_md_hbmc "Any Medicaid HH/HCBS 1999-2012"
label var medicaid_hbmc "Medicaid HH/HCBS in calendar year"

gen any_hbmc = 0
replace any_hbmc = 1 if any_mc_hbmc==1 | any_md_hbmc==1
label var any_hbmc "Any Medicare HBMC or Medicaid HH/HCBS 1998-2015"

label var all "# at Risk (Unqiue People)"
label var hh_part_b "Medicare HH claim Part B in calendar year"
label var medicaid_hh "Medicaid HH claim in calendar year"
gsort id -core_year

by id: gen death_sy = 1 if death_year==core_year
label var death_sy "Died after ivw in the same calendar year"
by id: gen death_ny = 1 if (death_year>core_year & _n==1 & death_year!=.)
label var death_ny "Last observed ivw, dies year(s) after ivw"

gsort id core_year
by id: gen obs=_n
by id: gen ltf = 1 if obs==_n & obs[_n+1]==.



local ivars death_sy death_ny nhres informal formal anyhelp nohelp both_flag hh_part_b medicaid_hh has_medicare has_medicaid medicaid_hbmc any_mc_hbmc any_md_hbmc any_hbmc all

local full: word count `ivars'
mat tab1=J(`full',9,.)
local r=1
local c=1

foreach x of local ivars {
	forvalues i=1/9 {
	sum `x' if dwave==`i'
	mat tab1[`r',`c']=r(sum)
	local ++c
	}
	
	local c = 1
	local ++r
	}
	
mat rownames tab1 = `ivars'

frmttable using `logpath'\HRS_P01_longitudinal_`date'.doc, addtable statmat(tab1) ///
varlabels title("HRS 1998-2014 with Community Dwelling + Dementia: Following People from Incident Dementia") ctitles("Variables", "Year 1", "Year 3", "Year 5", "Year 7", "Year 9", "Year 11", "Year 13", "Year 15", "Year 17") sdec(0) ///
note("Each Year represents a HRS core interview, which occurs every 2 years. Sample is pulled from HRS 1998-2014 core interviews.")


H="HRS - Inclusion Numbers"

/******* HRS Community Dwelling + Dementia *****************/

use "E:\data\HBMC_HRS\int_data\hrs_p01.dta", replace

cap drop _m
merge 1:1 id core_year using "E:\data\hrs_public_2014\dementia\pdem_withvarnames_00_14.dta", keepus(pdem)
keep if nhres==0
cap drop _m

preserve
gsort id core_year

by id: gen first_year = core_year if _n==1
keep id first_year
drop if first_year==.

save "E:\data\HBMC_HRS\int_data\firstcore.dta", replace
restore

replace per_part_b = hh_val_b if core_year>2000
replace hh_part_b = hh_val_p_b if core_year>2000

gen dementia = 0
replace dementia = 1 if pdem>=0.5 & pdem!=.

replace both_flag = 0
replace hh_claim = 0 if hh_claim==.
replace num_hh_claim = 0 if num_hh_claim==.
replace per_part_b = 0 if per_part_b==.
replace hh_part_b = 0 if hh_part_b==.
replace both_flag = 1 if cpt_flag==1 

local logpath "E:\data\HBMC_HRS\logs"
local date=subinstr("$S_DATE"," ","_",.)

gen all = 1

gen index_date = c_ivw_date

drop if c_ivw_date==.
merge 1:1 id index_date using "E:\data\HBMC_HRS\int_data\ffs_before.dta", keepus(cont_ffs_n_mos)
drop _m

gen both_hbmc = 0
replace both_hbmc = 1 if both_flag==1


gen hbmc_hh = 0
replace hbmc_hh = 1 if both_hbmc==1 & hh_claim==1

gen hbmc_nohh = 0
replace hbmc_nohh = 1 if both_hbmc==1 & hh_claim==0


gen ffs_6m = 0
replace ffs_6m = 1 if cont_ffs_n_mos>=6 & cont_ffs_n_mos!=.
label var ffs_6m "Has >=6m of Medicare FFS prior to ivw"

gen has_medicare = 0
replace has_medicare = 1 if bid_hrs_22!=""
label var has_medicare "Has Medicare Claims"

gen hbmc_n = 0
replace hbmc_n = 1 if cpt_flag_n>1 & cpt_flag_n!=.
label var hbmc_n "Indicator of multiple Medicare HBMC in calendar year"


gen dem_ffs = 0
replace dem_ffs = 1 if dementia==1 & ffs_6m==1

preserve
keep if dementia==1 & nhres==0
gsort id core_year
by id: gen firstdem = 1 if _n==1 // incident dementia
keep if firstdem==1
rename core_year incident_year
tempfile firstdem
save `firstdem'
restore

preserve
keep if both_flag==1
keep id
duplicates drop
gen any_mc_hbmc = 1
tempfile any
save `any'
restore

preserve
keep if medicaid_hbmc==1
keep id 
duplicates drop
gen any_md_hbmc = 1
tempfile any2
save `any2'
restore


merge m:1 id using "`firstdem'", keepus(incident_year firstdem)

gen firstdemhbmc = 0
replace firstdemhbmc = 1 if firstdem==1 & both_hbmc==1


foreach x of varlist hh_claim both_hbmc hbmc_n cpt_flag_n hh_claim hh_part_b hbmc_hh hbmc_nohh num_hh_claim num_hh_claim per_part_b {
replace `x' = 0 if dem_ffs==0
}

keep if dem_ffs==1
duplicates drop id, force


*collapse (max) all dementia dem_ffs, by(id)

//start with the HRS sample from the above tab

drop hisp
tempfile t1
save `t1'

use "E:\data\hrs_restricted_2014\Received\Race\2014\re20141\stata\RE2014.dta", clear
rename *, l
merge m:1 hhid pn using "E:\data\hrs_tracking_2014\trk2014tr_r.dta", ///
keep(match master) keepusing(gender)
rename gender gend2

gen racecat=1 if inlist(race1,3)
replace racecat=2 if inlist(race1,4)
replace racecat=4 if inlist(race1,2)
replace racecat=5 if inlist(race1,1)
replace racecat=7 if inlist(race1,7,8,9)
replace racecat=1 if inlist(race2m1,3,4)
replace racecat=2 if inlist(race2m1,5) 
replace racecat=3 if inlist(race2m1,6,7) 
replace racecat=4 if inlist(race2m1,2) 
replace racecat=5 if inlist(race2m1,1) 
replace racecat=6 if inrange(race2m2,1,98)
replace racecat=7 if inlist(race2m1,97,98,99,0) & missing(racecat)

label define racecat 1 "Amer. Indian/Alaska Native" 2 "Asian" 3 "Hawaiian/Pac Islander" 4 "Black" 5 "White" 6 ///
"Multiple" 7 "Unknown/Other"
label values racecat racecat

gen hisp=inrange(hispanic1,1,5) | inlist(hispanic2m1,1,2,3,7,8,9)
label var hisp "Hispanic"

keep hhid pn racecat hisp gend2

tempfile t2
save `t2'

use `t1', clear
drop _m
merge 1:1 hhid pn using `t2'
replace female=gend2-1 if missing(female)
keep if _m==3


H="NHATS - Sample Pull"
libname claims "E:\nhats\data\NHATS CMS DUA 28016\Merged\SAS";
libname cumu "E:\nhats\data\NHATS CMS DUA 28016\Cumulative";


data nhats_hh (keep = bene_id admit_year admit_date disch_date clm_srvc_clsfctn_type_cd per_part_b val_cd_part_a val_cd_part_b)  ;
set claims.hh_09_17;
admit_year = year(admit_date);
if clm_srvc_clsfctn_type_cd="2" then per_part_b = 1;
run;

proc freq data=nhats_hh; tables clm_srvc_clsfctn_type_cd; run;


proc sql; /*unique people per year */
create table nhats_hh_annual as select bene_id, admit_year,
count(admit_year ne .) as num_hh_claim,
count(per_part_b) as per_part_b,
sum(val_cd_part_a) as val_cd_part_a,
sum(val_cd_part_b) as val_cd_part_b
/* clm_hha_tot_visit_cnt as clm_hha_tot_visit_cnt */
from nhats_hh group by bene_id, admit_year;
quit;

proc freq data=nhats_hh_annual; tables per_part_b; run;

proc sort data=nhats_hh_annual out=nhats_hh_total nodupkey; by bene_id; run; /* unique people */

data nhats_hh_annual;
set nhats_hh_annual;
hh_claim = 1;
hh_part_b = 0;
if per_part_b>0 then hh_part_b = 1;
hh_val_a = 0;
hh_val_b = 0;
if val_cd_part_a>0 then hh_val_a = 1;
if val_cd_part_b>0 then hh_val_b = 1;
run;

proc freq data=nhats_hh_annual; tables hh_claim hh_part_b; run;

/*
proc sql;
create table nhats_hh_annual2 as select distinct admit_year,
sum(hh_claim) as mc_hh_claim
from nhats_hh_annual group by admit_year;
quit;

data nhats_hh_total;
set nhats_hh_total;
hh_claim = 1;
admit_year = 2018;
run;

proc sql;
create table nhats_hh_total2 as select distinct admit_year,
sum(hh_claim) as mc_hh_claim
from nhats_hh_total group by admit_year;
quit;

data nhats_hh_annual3;
set nhats_hh_annual2 nhats_hh_total2;
by admit_year;
run; 


proc export data=nhats_hh_annual3 outfile="E:\data\HBMC_HRS\int_data\nhats_hh.dta" dbms=stata replace; run;

*/



/********** Identifying house calls ************/

/* Identifying house calls */

data carrier;
set claims.pb_09_17;
admit_year = year(admit_date);
array dx hcpcscd1--hcpcscd13;
do over dx;
hcpcs_cd=dx;
output;
end;
run;

data carrier1;
set carrier;
cptcodes1 = input(compress(hcpcs_cd,'ABCDEFGHIJKLMNOPQRSTUVWXYZ/',),8.);
run;

data carrier1;
set carrier1;
cpt1flag = 0;
if 99341<=cptcodes1<=99350 or 99324<=cptcodes1<=99328 or 99334<=cptcodes1<=99337 then cpt1flag = 1;
run;

/* CPT1FLAG = Housecalls cpt codes found in carrier base file */
data carrier1;
set carrier1;
where cpt1flag = 1;
run;


/* Looking for housecall cptcodes in carrier line file */
data carrierline (keep = bene_id clm_id LINE_PLACE_OF_SRVC_CD cptcodes);
set cumu.bcarrier_line_j_09_17;
cptcodes = input(compress(hcpcs_cd,'ABCDEFGHIJKLMNOPQRSTUVWXYZ/',),8.);
run;


* temporarily removing POS as a requirement for home based care;

data carrierline;
set carrierline;
if 99341<=cptcodes<=99350 or 99324<=cptcodes<=99328 or 99334<=cptcodes<=99337 then cptflag=1;
/* if LINE_PLACE_OF_SRVC_CD in:(12,13,14) then posflag=1 */;
run;

proc freq data=carrierline; tables cptflag; run;

data linecalls;
set carrierline;
where cptflag = 1 /*or posflag = 1*/;
run;

proc sql;
create table carrier2 as select a.*, b.*
from carrier1 a
full outer join linecalls b
on a.bene_id=b.bene_id and a.clm_id = b.clm_id;
quit;

data carrier2;
set carrier2;
where cptflag = 1 or cpt1flag = 1; *or posflag = 1;
admit_year = year(admit_date);
run;

proc sort data=carrier2 out=carrier3 nodupkey; by bene_id; run;

proc freq data=carrier2; tables cptflag cpt1flag; run;

data carrier2;
set carrier2;
both_flag = 0;
if (cptflag=1 or cpt1flag=1) /* and posflag=1 */ then both_flag =1;
if (cptflag=1 or cpt1flag=1) then cptflag=1;
run;

data carrier2;
set carrier2;
where cptflag = 1;
run;

proc sort data=carrier2 nodupkey; by bene_id clm_id; run;

proc sql;
create table pb_annual as select distinct bene_id, admit_year,
sum(cptflag) as cptflag_n,
/* sum(posflag) as posflag_n, */
sum(both_flag) as both_flag_n
from carrier2
group by bene_id, admit_year;
quit;


data pb_annual;
set pb_annual;
cptflag = 0;
*posflag = 0;
both_flag = 0;
if cptflag_n>=1 then cptflag=1;
*if posflag_n>=1 then posflag=1;
if both_flag_n>=1 then both_flag=1;
run;

proc sql;
create table nhats as select a.*, b.cptflag, b.both_flag, b.cptflag_n, b.both_flag_n
from nhats_hh_annual a
left join pb_annual b 
on a.bene_id=b.bene_id and a.admit_year=b.admit_year;
quit;

data nhats (rename=(admit_year=index_year));
set nhats;
run;

proc export data=nhats outfile="E:\data\HBMC_HRS\int_data\nhats_claims.dta" replace; run;

H="NHATS - Longitudinal Table"
use "E:\nhats\data\Projects\serious_ill\int_data\serious_ill_int_dataset1.dta", replace

gen ffs_6m = 0
replace ffs_6m = 1 if cont_ffs_n_mos>=6 & cont_ffs_n_mos!=.

merge 1:1 bene_id index_year using "E:\data\HBMC_HRS\int_data\nhats_claims.dta"
drop if _m==2



local logpath "E:\data\HBMC_HRS\logs"
local date=subinstr("$S_DATE"," ","_",.)

gen all = 1

replace hh_part_b = hh_val_b // replacing type service with value code for binary part b indicator
replace per_part_b = val_cd_part_b // replacing type service with value code for binary part b indicator
replace prob_dem = 0 if prob_dem==.

replace both_flag = 0
replace hh_claim = 0 if hh_claim==.
replace num_hh_claim = 0 if num_hh_claim==.
replace per_part_b = 0 if per_part_b==.
replace hh_part_b = 0 if hh_part_b==.
replace both_flag = 1 if cptflag==1 

gen dem_ffs = 0
replace dem_ffs = 1 if prob_dem==1 & ffs_6m==1 

gen both_hbmc = 0
replace both_hbmc = 1 if reg_doc_homevisit==1 | both_flag==1

gen unrestr_hbmc = both_hbmc

/*Renumbering waves for new cohort */
replace wave=1 if old_cohort==0 & wave==5
replace wave=2 if old_cohort==0 & wave==6
replace wave=3 if old_cohort==0 & wave==7

/* Project wants to identify people with CD + 6m FFS + dementia in Wave 1 (Old cohort) or Wave 5 (New Cohort) */

gen dem_cohort = 0
replace dem_cohort = 1 if wave==1 & community_dwelling==1 & prob_dem==1

levelsof spid if dem_cohort==1, local(dementia)

foreach x of local dementia {

replace dem_cohort = 1 if spid==`x' & wave>1
}

keep if dem_cohort==1

gen informal = 0
replace informal = 1 if ind_family_helper==1 | otherinformal_help_ind==1

gen anyhelp = 0
replace anyhelp = 1 if paid_help_ind==1 | informal==1

label var informal "Any unpaid helpers"
label var anyhelp "Any Paid/Unpaid Helpers"
label var both_flag "Medicare HBMC"
label var both_hbmc "Self Report or Medicare HBMC"
label var all "# at Risk (Unique People)"

gsort spid -index_year

by spid: gen death_sy = 1 if death_year==index_year
label var death_sy "Died after ivw in the same calendar year"
by spid: gen death_ny = 1 if (death_year>index_year & _n==1 & death_year!=.)
label var death_ny "Last observed ivw, dies year(s) after ivw"
local ivars death_sy death_ny nhres informal ind_paid_helper ind_no_helpers anyhelp both_flag reg_doc_homevisit any_hbmc both_hbmc any_bothhbmc all
label var hh_part_b "Medicare HH Part B Claim"

gen death = 0
replace death = 1 if death_sy==1 | death_ny==1
label var death "Died"


gsort spid index_year
by spid: gen obs=_n
by spid: gen ltf = 1 if obs==_n & obs[_n+1]==.
by spid: gen died_ltf = 1 if death[_n-1]==1
by spid: gen ltf2 = ltf[_n-1]

replace ltf2 = . if died_ltf==1
label var ltf2 "Loss to followup"

label var ltf "Loss to followup"
label var died_ltf "Death"
replace died_ltf = 0 if died_ltf==.
replace all = all + died_ltf

gen both_hbmc2 = 0
gen all_hbmc = both_hbmc
replace all_hbmc = 0 if nhres==1
label var all_hbmc "Any HBMC 2011-2017"

by spid: replace both_hbmc2 = 1 if both_hbmc==1 | both_hbmc2[_n-1]==1
label var both_hbmc2 "Cumulative Self Report or Claims HBMC"
tempfile hbmc 
save `hbmc'

replace both_hbmc = 0 if nhres==1
replace hh_part_b = 0 if nhres==1 | both_hbmc==1
replace anyhelp = 0 if nhres==1 | both_hbmc==1 | hh_part_b==1



gen no_support = 1
replace no_support = 0 if nhres==1 | both_hbmc==1 | hh_part_b==1 | anyhelp==1


local ivars died_ltf nhres both_hbmc hh_part_b anyhelp no_support all

local full: word count `ivars' all_hbmc
mat tab1=J(`full', 7,.)
local r = 1
local c = 1
 
preserve
 
foreach x of local ivars {

forvalues i = 1/7 {
	
sum `x' if wave==`i'
mat tab1[`r',`c'] = r(sum)

local ++c
}

local c = 1
local ++r
}

replace all = 1

local c = 1


collapse (max) all_hbmc, by(spid)



sum all_hbmc

mat tab1[`r',1] = r(sum)

restore 
label var all_hbmc "Any HBMC 2011-2017"

mat rownames tab1 = `ivars' all_hbmc

mat list tab1

frmttable using `logpath'\NHATS_P01_longitudinal`date'.doc, replace statmat(tab1) ///
varlabels title("NHATS 2011-2017: Following People from Wave 1(Original Cohort)/5(New Cohort) Dementia+Community Dwelling+6m FFS") ctitles("Variables", "Year 1", "Year 2", "Year 3", "Year 4", "Year 5", "Year 6", "Year 7") sdec(0) ///
note("Community Dwelling + 6m FFS + Dementia at first wave only (Year 1). Categories are mututally exclusive in decending order.")

use `hbmc', clear


replace both_hbmc2 = 0 if nhres==1
replace hh_part_b = 0 if nhres==1 | both_hbmc2==1
replace anyhelp = 0 if nhres==1 | both_hbmc2==1 | hh_part_b==1



gen no_support = 1
replace no_support = 0 if nhres==1 | both_hbmc2==1 | hh_part_b==1 | anyhelp==1


local ivars died_ltf nhres both_hbmc2 hh_part_b anyhelp no_support all

local full: word count `ivars' all_hbmc
mat tab1=J(`full', 7,.)
local r = 1
local c = 1
 
preserve
 
foreach x of local ivars {

forvalues i = 1/7 {
	
sum `x' if wave==`i'
mat tab1[`r',`c'] = r(sum)

local ++c
}

local c = 1
local ++r
}

replace all = 1

local c = 1

collapse (max) all_hbmc, by(spid)

sum all_hbmc

mat tab1[`r',1] = r(sum)

restore
label var all_hbmc "Any HBMC 2011-2017"

mat rownames tab1 = `ivars' all_hbmc

frmttable using `logpath'\NHATS_P01_longitudinal`date'.doc, addtable statmat(tab1) ///
varlabels title("NHATS 2011-2017: Following People from Wave 1(Original Cohort)/5(New Cohort) Dementia+Community Dwelling+6m FFS") ctitles("Variables", "Year 1", "Year 2", "Year 3", "Year 4", "Year 5", "Year 6", "Year 7") sdec(0) ///
note("Community Dwelling + 6m FFS + Dementia at first wave only (Year 1). Categories are mututally exclusive in decending order.")


H="NHATS - Sample Size Table"
/********* NHATS Community Dwelling + Dementia ***********/ 

use "E:\nhats\data\Projects\serious_ill\int_data\serious_ill_int_dataset1.dta", replace

keep if wave==1
cap drop old_cohort
gen old_cohort = 1
label var old_cohort "Original Cohort in Wave 1"
tempfile old

save `old'

use "E:\nhats\data\Projects\serious_ill\int_data\serious_ill_int_dataset1.dta", clear
cap drop _m
merge m:1 spid using "`old'", keepus(old_cohort) update replace
replace old_cohort=0 if old_cohort==.
cap drop _m
save "E:\nhats\data\Projects\serious_ill\int_data\serious_ill_int_dataset1.dta", replace

gen ffs_6m = 0
replace ffs_6m = 1 if cont_ffs_n_mos>=6 & cont_ffs_n_mos!=.

merge 1:1 bene_id index_year using "E:\data\HBMC_HRS\int_data\nhats_claims.dta"
drop if _m==2
keep if community_dwelling==1

replace hh_part_b = hh_val_b // replacing type service with value code for binary part b indicator
replace per_part_b = val_cd_part_b
replace prob_dem = 0 if prob_dem==.

replace both_flag = 0
replace hh_claim = 0 if hh_claim==.
replace num_hh_claim = 0 if num_hh_claim==.
replace per_part_b = 0 if per_part_b==.
replace hh_part_b = 0 if hh_part_b==.
replace both_flag = 1 if cptflag==1 


local logpath "E:\data\HBMC_HRS\logs"
local date=subinstr("$S_DATE"," ","_",.)

gen all = 1

gen dem_ffs = 0
replace dem_ffs = 1 if prob_dem==1 & ffs_6m==1 

gen both_hbmc = 0
replace both_hbmc = 1 if reg_doc_homevisit==1 | both_flag==1

gen unrestr_hbmc = both_hbmc

gen hbmc_hh = 0
replace hbmc_hh = 1 if both_hbmc==1 & hh_claim==1

gen hbmc_nohh = 0
replace hbmc_nohh = 1 if both_hbmc==1 & hh_claim==0

gen hbmc_n = 0
replace hbmc_n = 1 if cptflag_n>1 & cptflag_n!=.
label var hbmc_n "Indicator of multiple Medicare HBMC in calendar year"





/*
foreach x of varlist both_hbmc hh_claim hh_part_b hbmc_hh hbmc_nohh num_hh_claim per_part_b {
replace `x' = 0 if dem_ffs==0
}
*/

foreach x of varlist both_hbmc hbmc_n cptflag_n hh_claim hh_part_b hbmc_hh hbmc_nohh num_hh_claim per_part_b {
replace `x' = 0 if prob_dem==0
}




local cvars all prob_dem dem_ffs both_hbmc hbmc_n cptflag_n hh_claim hh_part_b hbmc_hh hbmc_nohh num_hh_claim num_hh_claim per_part_b


local full: word count `cvars'
di "`full'"
mat tab1=J(8,`full',.)
local r = 1
local c = 1



forvalues i=2011/2017 {

	foreach x of local cvars {
	
sum `x' if index_year==`i'
mat tab1[`r',`c'] = r(sum)

local ++c
}

local c = 1
local ++r
}
preserve

collapse (sum) num_hh_claim per_part_b cptflag_n, by(spid)
tempfile coll
save `coll'
restore

collapse (max) all prob_dem dem_ffs both_hbmc hbmc_n hh_claim hh_part_b hbmc_hh hbmc_nohh, by(spid)
merge 1:1 spid using `coll'

local c = 1
foreach x of local cvars {
	
sum `x' 
mat tab1[`r',`c'] = r(sum)

local ++c
}


forvalues i = 1/8 {

mat tab1[`i',6] = tab1[`i',6]/tab1[`i',4]
mat tab1[`i',12] = tab1[`i',12]/tab1[`i',7]
mat tab1[`i',13] = ((tab1[`i',13]/tab1[`i',11])*100)
}

mat rownames tab1 ="2011" "2012" "2013" "2014" "2015" "2016" "2017" "Unique People"


frmttable using `logpath'\NHATS_P01_SampleSize_`date'.doc, replace statmat(tab1) ///
varlabels title("NHATS Community Dwelling + Dementia 2011-2017: Prevelance/Cross-Section ") ctitles("Year", "Full Sample", "Dementia (N)", "Dementia + 6m FFS", "Self Report or Claims HBMC", "Multiple Claims HBMC in Calendar Year", "Ave. # of Claims HBMC in Calendar Year","Medicare HH", "Medicare HH Part B", "HBMC + HH" "HBMC, no HH", "Total # of HHA episodes", "Ave. # of HHA episodes", "% of HHA episodes Part B") sdec(0,0,0,0,0,2,0,0,0,0,0,2,2) ///
/*colwidth(11,7,7,7,7,7,7,7,7,7,7,7,7)*/ note("Restricted to Community Dwelling + Dementia at every wave. No FFS restriction. Ave # of HHA episodes is conditional on having a HHA episode. Ave # of HBMC Claims is conditional on having a HBMC claim.")

/********* NHATS Community Dwelling + Dementia --- UNIQUE HBMC ***********/ 


use "E:\nhats\data\Projects\serious_ill\int_data\serious_ill_int_dataset1.dta", clear

gen ffs_6m = 0
replace ffs_6m = 1 if cont_ffs_n_mos>=6 & cont_ffs_n_mos!=.

merge 1:1 bene_id index_year using "E:\data\HBMC_HRS\int_data\nhats_claims.dta"
drop if _m==2
keep if community_dwelling==1

replace hh_part_b = hh_val_b // replacing type service with value code for binary part b indicator
replace per_part_b = val_cd_part_b
replace prob_dem = 0 if prob_dem==.

replace both_flag = 0
replace hh_claim = 0 if hh_claim==.
replace num_hh_claim = 0 if num_hh_claim==.
replace per_part_b = 0 if per_part_b==.
replace hh_part_b = 0 if hh_part_b==.
replace both_flag = 1 if cptflag==1 

gen all = 1

gen dem_ffs = 0
replace dem_ffs = 1 if prob_dem==1 & ffs_6m==1 

gen both_hbmc = 0
replace both_hbmc = 1 if reg_doc_homevisit==1 | both_flag==1

gen unrestr_hbmc = both_hbmc

gen hbmc_hh = 0
replace hbmc_hh = 1 if both_hbmc==1 & hh_claim==1

gen hbmc_nohh = 0
replace hbmc_nohh = 1 if both_hbmc==1 & hh_claim==0

/*
foreach x of varlist both_hbmc hh_claim hh_part_b hbmc_hh hbmc_nohh num_hh_claim per_part_b {
replace `x' = 0 if dem_ffs==0
}
*/

foreach x of varlist both_hbmc hh_claim hh_part_b hbmc_hh hbmc_nohh num_hh_claim per_part_b {
replace `x' = 0 if prob_dem==0
}

gen py = 1
replace py = py*wave if old_cohort==1
replace py = py*(wave-4) if old_cohort==0



forvalues i=1/7 {
gen hbmc_`i' = 0
replace hbmc_`i' = 1 if both_hbmc==1 & wave==`i'

levelsof bene_id if hbmc_`i'==1, local(hb)

foreach y of local hb {

drop if bene_id=="`y'" & wave>`i'

}
}

local cvars both_hbmc

local full: word count `cvars' 1 1 1
di "`full'"
mat tab1=J(8,`full',.)
local r = 1
local c = 1



forvalues i=2011/2017 {


	
sum both_hbmc if index_year==`i'
mat tab1[`r',1] = r(sum)


local p = `r'-2
local q = `r'-1

if `r'>=3 mat tab1[`r',2] = (tab1[`p',1] + tab1[`q',1] +  tab1[`r',1])/3


local ++r

}

sum all if both_hbmc==1
mat tab1[`r',1] = r(sum)

local r = 1



forvalues i = 2011/2017 {

sum py if both_hbmc==1 & index_year==`i'
mat tab1[`r',3] = r(sum)
mat tab1[`r',4] = (tab1[`r',3]/tab1[`r',1])


local ++r
}

sum py if both_hbmc==1
mat tab1[8,3] = r(sum)
mat tab1[8,4] = (tab1[8,3]/tab1[8,1])


mat rownames tab1 ="2011" "2012" "2013" "2014" "2015" "2016" "2017" "Cumulative"


frmttable using `logpath'\NHATS_P01_SampleSize_`date'.doc, addtable statmat(tab1) ///
varlabels title("NHATS Community Dwelling + Dementia 2011-2017: Unique HBMC added each year") ctitles("Year", "Self Report or Claims HBMC", "3-Yr Moving Average HBMC", "Follow Time from Enrollment (Person Years)", "Average Follow Time from Enrollment (Person Years)") sdec(0,1,0,2) ///
note("Restricted to Community Dwelling + Dementia at every wave. No FFS restriction.")


/****** NHATS Comunnity Dwelling + Dementia + 6m FFS **********/

use "E:\nhats\data\Projects\serious_ill\int_data\serious_ill_int_dataset1.dta", clear

gen ffs_6m = 0
replace ffs_6m = 1 if cont_ffs_n_mos>=6 & cont_ffs_n_mos!=.

merge 1:1 bene_id index_year using "E:\data\HBMC_HRS\int_data\nhats_claims.dta"
drop if _m==2
keep if community_dwelling==1

replace hh_part_b = hh_val_b // replacing type service with value code for binary part b indicator
replace per_part_b = val_cd_part_b
replace prob_dem = 0 if prob_dem==.

replace both_flag = 0
replace hh_claim = 0 if hh_claim==.
replace num_hh_claim = 0 if num_hh_claim==.
replace per_part_b = 0 if per_part_b==.
replace hh_part_b = 0 if hh_part_b==.
replace both_flag = 1 if cptflag==1 


local logpath "E:\data\HBMC_HRS\logs"
local date=subinstr("$S_DATE"," ","_",.)

gen all = 1

gen dem_ffs = 0
replace dem_ffs = 1 if prob_dem==1 & ffs_6m==1 

gen both_hbmc = 0
replace both_hbmc = 1 if reg_doc_homevisit==1 | both_flag==1

gen unrestr_hbmc = both_hbmc

gen hbmc_hh = 0
replace hbmc_hh = 1 if both_hbmc==1 & hh_claim==1

gen hbmc_nohh = 0
replace hbmc_nohh = 1 if both_hbmc==1 & hh_claim==0

gen hbmc_n = 0
replace hbmc_n = 1 if cptflag_n>1 & cptflag_n!=.
label var hbmc_n "Indicator of multiple Medicare HBMC in calendar year"





/*
foreach x of varlist both_hbmc hh_claim hh_part_b hbmc_hh hbmc_nohh num_hh_claim per_part_b {
replace `x' = 0 if dem_ffs==0
}
*/

foreach x of varlist both_hbmc hbmc_n cptflag_n hh_claim hh_part_b hbmc_hh hbmc_nohh num_hh_claim per_part_b {
replace `x' = 0 if dem_ffs==0
}




local cvars all prob_dem dem_ffs both_hbmc hbmc_n cptflag_n hh_claim hh_part_b hbmc_hh hbmc_nohh num_hh_claim num_hh_claim per_part_b


local full: word count `cvars'
di "`full'"
mat tab1=J(8,`full',.)
local r = 1
local c = 1



forvalues i=2011/2017 {

	foreach x of local cvars {
	
sum `x' if index_year==`i'
mat tab1[`r',`c'] = r(sum)

local ++c
}

local c = 1
local ++r
}
preserve

collapse (sum) num_hh_claim per_part_b cptflag_n, by(spid)
tempfile coll
save `coll'
restore

collapse (max) all prob_dem dem_ffs both_hbmc hbmc_n hh_claim hh_part_b hbmc_hh hbmc_nohh, by(spid)
merge 1:1 spid using `coll'

local c = 1
foreach x of local cvars {
	
sum `x' 
mat tab1[`r',`c'] = r(sum)

local ++c
}


forvalues i = 1/8 {

mat tab1[`i',6] = tab1[`i',6]/tab1[`i',4]
mat tab1[`i',12] = tab1[`i',12]/tab1[`i',7]
mat tab1[`i',13] = ((tab1[`i',13]/tab1[`i',11])*100)
}

mat rownames tab1 ="2011" "2012" "2013" "2014" "2015" "2016" "2017" "Unique People"

frmttable using `logpath'\NHATS_P01_SampleSize_`date'.doc, addtable statmat(tab1) ///
varlabels title("NHATS Community Dwelling + Dementia + 6m FFS 2011-2017: Prevelance/Cross-Section ") ctitles("Year", "Full Sample", "Dementia (N)", "Dementia + 6m FFS", "Self Report or Claims HBMC", "Multiple Claims HBMC in Calendar Year", "Ave. # of Claims HBMC in Calendar Year","Medicare HH", "Medicare HH Part B", "HBMC + HH" "HBMC, no HH", "Total # of HHA episodes", "Ave. # of HHA episodes", "% of HHA episodes Part B") sdec(0,0,0,0,0,2,0,0,0,0,0,2,2) ///
note("Restricted to Community Dwelling + Dementia at every wave. No FFS restriction. Ave # of HHA episodes is conditional on having a HHA episode. Ave # of HBMC Claims is conditional on having a HBMC claim.")


/****** NHATS Comunnity Dwelling + Dementia + 6m FFS :::: UNIQUE HBMC ADDED EACH YEAR **********/

use "E:\nhats\data\Projects\serious_ill\int_data\serious_ill_int_dataset1.dta", clear

gen ffs_6m = 0
replace ffs_6m = 1 if cont_ffs_n_mos>=6 & cont_ffs_n_mos!=.

merge 1:1 bene_id index_year using "E:\data\HBMC_HRS\int_data\nhats_claims.dta"
drop if _m==2
keep if community_dwelling==1

replace hh_part_b = hh_val_b // replacing type service with value code for binary part b indicator
replace per_part_b = val_cd_part_b
replace prob_dem = 0 if prob_dem==.

replace both_flag = 0
replace hh_claim = 0 if hh_claim==.
replace num_hh_claim = 0 if num_hh_claim==.
replace per_part_b = 0 if per_part_b==.
replace hh_part_b = 0 if hh_part_b==.
replace both_flag = 1 if cptflag==1 


local logpath "E:\data\HBMC_HRS\logs"
local date=subinstr("$S_DATE"," ","_",.)

gen all = 1

gen dem_ffs = 0
replace dem_ffs = 1 if prob_dem==1 & ffs_6m==1 

gen both_hbmc = 0
replace both_hbmc = 1 if reg_doc_homevisit==1 | both_flag==1

gen unrestr_hbmc = both_hbmc

gen hbmc_hh = 0
replace hbmc_hh = 1 if both_hbmc==1 & hh_claim==1

gen hbmc_nohh = 0
replace hbmc_nohh = 1 if both_hbmc==1 & hh_claim==0

/*
foreach x of varlist both_hbmc hh_claim hh_part_b hbmc_hh hbmc_nohh num_hh_claim per_part_b {
replace `x' = 0 if dem_ffs==0
}
*/

foreach x of varlist both_hbmc hh_claim hh_part_b hbmc_hh hbmc_nohh num_hh_claim per_part_b {
replace `x' = 0 if dem_ffs==0
}

gen py = 1
replace py = py*wave if old_cohort==1
replace py = py*(wave-4) if old_cohort==0

forvalues i=1/7 {
gen hbmc_`i' = 0
replace hbmc_`i' = 1 if both_hbmc==1 & wave==`i'

levelsof bene_id if hbmc_`i'==1, local(hb)

foreach y of local hb {

drop if bene_id=="`y'" & wave>`i'

}
}



local cvars both_hbmc

local full: word count `cvars' 1 1 1
di "`full'"
mat tab1=J(8,`full',.)
local r = 1
local c = 1



forvalues i=2011/2017 {


	
sum both_hbmc if index_year==`i'
mat tab1[`r',1] = r(sum)


local p = `r'-2
local q = `r'-1

if `r'>=3 mat tab1[`r',2] = (tab1[`p',1] + tab1[`q',1] +  tab1[`r',1])/3


local ++r

}

sum all if both_hbmc==1
mat tab1[`r',1] = r(sum)

local r = 1



forvalues i = 2011/2017 {

sum py if both_hbmc==1 & index_year==`i'
mat tab1[`r',3] = r(sum)
mat tab1[`r',4] = (tab1[`r',3]/tab1[`r',1])


local ++r
}

sum py if both_hbmc==1
mat tab1[8,3] = r(sum)
mat tab1[8,4] = (tab1[8,3]/tab1[8,1])

mat rownames tab1 ="2011" "2012" "2013" "2014" "2015" "2016" "2017" "Cumulative"


frmttable using `logpath'\NHATS_P01_SampleSize_`date'.doc, addtable statmat(tab1) ///
varlabels title("NHATS Community Dwelling + Dementia + 6m FFS 2011-2017: Unique HBMC added each year") ctitles("Year", "Self Report or Claims HBMC", "3-Yr Moving Average HBMC", "Follow Time from Enrollment (Person Years)", "Average Follow Time from Enrollment (Person Years)") sdec(0,1,0,2) ///
note("Restricted to Community Dwelling + Dementia + 6m FFS at every wave.")


H="NHATS - Sample Comparison"
/****** NHATS Comunnity Dwelling + Dementia + 6m FFS **********/

use "E:\nhats\data\Projects\serious_ill\int_data\serious_ill_int_dataset1.dta", clear

gen ffs_6m = 0
replace ffs_6m = 1 if cont_ffs_n_mos>=6 & cont_ffs_n_mos!=.

merge 1:1 bene_id index_year using "E:\data\HBMC_HRS\int_data\nhats_claims.dta"
drop if _m==2

replace hh_part_b = hh_val_b // replacing type service with value code for binary part b indicator
replace per_part_b = val_cd_part_b
replace prob_dem = 0 if prob_dem==.

replace both_flag = 0
replace hh_claim = 0 if hh_claim==.
replace num_hh_claim = 0 if num_hh_claim==.
replace per_part_b = 0 if per_part_b==.
replace hh_part_b = 0 if hh_part_b==.
replace both_flag = 1 if cptflag==1 

local logpath "E:\data\HBMC_HRS\logs"
local date=subinstr("$S_DATE"," ","_",.)

gen all = 1

gen dem_ffs = 0
replace dem_ffs = 1 if prob_dem==1 & ffs_6m==1 

gen both_hbmc = 0
replace both_hbmc = 1 if reg_doc_homevisit==1 | both_flag==1

gen unrestr_hbmc = both_hbmc

gen hbmc_hh = 0
replace hbmc_hh = 1 if both_hbmc==1 & hh_claim==1

gen hbmc_nohh = 0
replace hbmc_nohh = 1 if both_hbmc==1 & hh_claim==0

gen hbmc_n = 0
replace hbmc_n = 1 if cptflag_n>1 & cptflag_n!=.
label var hbmc_n "Indicator of multiple Medicare HBMC in calendar year"

tempfile tables 
save `tables'

gsort spid wave
preserve
keep if prob_dem==1
keep if community_dwelling==1
by spid: gen firstdem = 1 if _n==1 // first wave where dementia is observed
gen anydem =1 // any dementia in NHATS
keep spid wave firstdem anydem
tempfile firstdem
save `firstdem'
keep if firstdem==1
rename wave inc_wave
duplicates drop spid, force
tempfile anydem
save `anydem'

restore

cap drop _m
merge 1:1 spid wave using "`firstdem'", keepus(firstdem)
cap drop _m
merge m:1 spid using "`anydem'", keepus(anydem inc_wave) 

gen firstdemhbmc = 0
replace firstdemhbmc = 1 if firstdem==1 & both_hbmc==1


keep if community_dwelling==1

foreach x of varlist both_hbmc hbmc_n cptflag_n hh_claim hh_part_b hbmc_hh hbmc_nohh num_hh_claim per_part_b firstdem firstdemhbmc {
replace `x' = 0 if dem_ffs==0
}

local cvars all prob_dem dem_ffs both_hbmc firstdem firstdemhbmc

local full: word count `cvars'
di "`full'"
mat tab1=J(8,`full',.)
local r = 1
local c = 1


forvalues i=2011/2017 {

	foreach x of local cvars {
	
sum `x' if index_year==`i'
mat tab1[`r',`c'] = r(sum)

local ++c
}

local c = 1
local ++r
}
preserve

collapse (sum) num_hh_claim per_part_b cptflag_n, by(spid)
tempfile coll
save `coll'
restore

collapse (max) all prob_dem dem_ffs both_hbmc hbmc_n hh_claim hh_part_b hbmc_hh hbmc_nohh firstdem firstdemhbmc, by(spid)
merge 1:1 spid using `coll'

local c = 1
foreach x of local cvars {
	
sum `x' 
mat tab1[`r',`c'] = r(sum)

local ++c
}



mat rownames tab1 ="2011" "2012" "2013" "2014" "2015" "2016" "2017" "Unique People"

frmttable using `logpath'\NHATS_P01_SampleDifferences`date'.doc, replace statmat(tab1) ///
varlabels title("NHATS Community Dwelling + Dementia + 6m FFS 2011-2017: Cross-Sectional vs Longitudinal ") ctitles("Year", "Full Sample", "Dementia (N)", "Dementia + 6m FFS", "Self Report or Claims HBMC (Cross-Sectional Sample)", "Incident Dementia + 6m FFS", "Incident Dementia + 6m FFS + HBMC (Longitudinal Sample)") sdec(0) ///
note("Restricted to Community Dwelling + Dementia at every wave.")

use `tables', clear


/*Renumbering waves for new cohort */
replace wave=1 if old_cohort==0 & wave==5
replace wave=2 if old_cohort==0 & wave==6
replace wave=3 if old_cohort==0 & wave==7

gsort spid wave
preserve
keep if prob_dem==1
keep if community_dwelling==1
by spid: gen firstdem = 1 if _n==1 // first wave where dementia is observed
gen anydem =1 // any dementia in NHATS
keep spid wave firstdem anydem
tempfile firstdem
save `firstdem'
keep if firstdem==1
rename wave inc_wave
duplicates drop spid, force
tempfile anydem
save `anydem'

restore

cap drop _m
merge 1:1 spid wave using "`firstdem'", keepus(firstdem)
cap drop _m
merge m:1 spid using "`anydem'", keepus(anydem inc_wave) 
keep if _m==3


drop if wave<inc_wave

gsort spid wave

by spid: gen dwave = _n

/*
levelsof spid if community_dwelling==1 & wave==1, local(keep)


gen keeplist =0
foreach x of local keep {
replace keeplist = 1 if spid==`x'
}
keep if keeplist==1
*/

gen informal = 0
replace informal = 1 if ind_family_helper==1 | otherinformal_help_ind==1

gen anyhelp = 0
replace anyhelp = 1 if paid_help_ind==1 | informal==1

label var informal "Any unpaid helpers"
label var anyhelp "Any Paid/Unpaid Helpers"
label var both_flag "Medicare HBMC"
label var all "# at Risk (Unique People)"

preserve
tempfile hbmc
keep if both_flag==1
gen any_hbmc = 1
keep spid any_hbmc
duplicates drop spid, force
save `hbmc'
restore

preserve
tempfile hbmc2
keep if both_hbmc==1
gen any_bothhbmc = 1
keep spid any_bothhbmc
duplicates drop spid, force
save `hbmc2'
restore


cap drop _m
merge m:1 spid using "`hbmc'", keepus(any_hbmc) 
drop _m
merge m:1 spid using "`hbmc2'", keepus(any_bothhbmc)
drop _m
label var any_hbmc "Any Medicare HBMC 2011-17"
label var any_bothhbmc "Self Report or Medicare HBMC 2011-17"
label var reg_doc_homevisit "Self Report HBMC"
label var both_hbmc "Self Report or Medicare HBMC"

gsort spid -index_year

by spid: gen death_sy = 1 if death_year==index_year
label var death_sy "Died after ivw in the same calendar year"
by spid: gen death_ny = 1 if (death_year>index_year & _n==1 & death_year!=.)
label var death_ny "Last observed ivw, dies year(s) after ivw"
local ivars death_sy death_ny nhres informal ind_paid_helper ind_no_helpers anyhelp both_flag reg_doc_homevisit any_hbmc both_hbmc any_bothhbmc all
label var hh_part_b "Medicare HH Part B Claim"

gsort spid index_year
by spid: gen obs=_n
by spid: gen ltf = 1 if obs==_n & obs[_n+1]==.


/*
frmttable using `logpath'\NHATS_P01_longitudinal_`date'.doc, addtable statmat(tab1) ///
varlabels title("NHATS 2011-2017: Following People from Incident Dementia+Community Dwelling") ctitles("Variables", "Year 1", "Year 2", "Year 3", "Year 4", "Year 5", "Year 6", "Year 7") sdec(0) ///
note("People must be community dwelling at incident wave only (Year 1). Medicare HBMC not restricted by POS")
*/

gen keeplist = 0

levelsof spid if ffs_6m==1 & dwave==1, local(keeplist)

foreach x of local keeplist {

replace keeplist = 1 if spid==`x'
}

keep if keeplist==1

replace both_hbmc = 0 if nhres==1
replace hh_part_b = 0 if nhres==1 | both_hbmc==1
replace anyhelp = 0 if nhres==1 | both_hbmc==1 | hh_part_b==1


gen death = 0
replace death = 1 if death_sy==1 | death_ny==1
label var death "Died"


gen no_support = 1
replace no_support = 0 if nhres==1 | both_hbmc==1 | hh_part_b==1 | anyhelp==1

label var ltf "Loss to followup"

local ivars nhres both_hbmc hh_part_b anyhelp no_support all 
local ivars2 death

local full: word count `ivars' `ivars2'
mat tab1=J(`full', 7,.)
local r = 1
local c = 1
 

 
foreach x of local ivars {

forvalues i = 1/7 {
	
sum `x' if dwave==`i'
mat tab1[`r',`c'] = r(sum)

local ++c
}

local c = 1
local ++r
}


local c = 2

forvalues i = 1/6 {
	
sum death if dwave==`i'
mat tab1[`r',`c'] = r(sum)

local ++c
}



mat rownames tab1 = `ivars' `ivars2'

mat list tab1


frmttable using `logpath'\NHATS_P01_SampleDifferences`date'.doc, addtable statmat(tab1) ///
varlabels title("NHATS 2011-2017: Longitudinal Sample (Incident Dementia+Community Dwelling+6m FFS)") ctitles("Variables", "Year 1", "Year 2", "Year 3", "Year 4", "Year 5", "Year 6", "Year 7") sdec(0) ///
note("People must be community dwelling and >=6m FFS at incident wave only (Year 1). Categories are Mutually Exclusive in Descending Order.")




H="NHATS - Inclusion Table"
/********* NHATS Community Dwelling + Dementia ***********/ 

use "E:\nhats\data\Projects\serious_ill\int_data\serious_ill_int_dataset1.dta", replace

keep if wave==1
cap drop old_cohort
gen old_cohort = 1
label var old_cohort "Original Cohort in Wave 1"
tempfile old

save `old'

use "E:\nhats\data\Projects\serious_ill\int_data\serious_ill_int_dataset1.dta", clear
cap drop _m
merge m:1 spid using "`old'", keepus(old_cohort) update replace
replace old_cohort=0 if old_cohort==.
cap drop _m
save "E:\nhats\data\Projects\serious_ill\int_data\serious_ill_int_dataset1.dta", replace

gen ffs_6m = 0
replace ffs_6m = 1 if cont_ffs_n_mos>=6 & cont_ffs_n_mos!=.

merge 1:1 bene_id index_year using "E:\data\HBMC_HRS\int_data\nhats_claims.dta"
drop if _m==2
keep if community_dwelling==1

replace hh_part_b = hh_val_b // replacing type service with value code for binary part b indicator
replace per_part_b = val_cd_part_b
replace prob_dem = 0 if prob_dem==.

replace both_flag = 0
replace hh_claim = 0 if hh_claim==.
replace num_hh_claim = 0 if num_hh_claim==.
replace per_part_b = 0 if per_part_b==.
replace hh_part_b = 0 if hh_part_b==.
replace both_flag = 1 if cptflag==1 


local logpath "E:\data\HBMC_HRS\logs"
local date=subinstr("$S_DATE"," ","_",.)

gen all = 1

gen dem_ffs = 0
replace dem_ffs = 1 if prob_dem==1 & ffs_6m==1 

gen both_hbmc = 0
replace both_hbmc = 1 if reg_doc_homevisit==1 | both_flag==1

gen unrestr_hbmc = both_hbmc

gen hbmc_hh = 0
replace hbmc_hh = 1 if both_hbmc==1 & hh_claim==1

gen hbmc_nohh = 0
replace hbmc_nohh = 1 if both_hbmc==1 & hh_claim==0

gen hbmc_n = 0
replace hbmc_n = 1 if cptflag_n>1 & cptflag_n!=.
label var hbmc_n "Indicator of multiple Medicare HBMC in calendar year"



/*
foreach x of varlist both_hbmc hh_claim hh_part_b hbmc_hh hbmc_nohh num_hh_claim per_part_b {
replace `x' = 0 if dem_ffs==0
}
*/

foreach x of varlist both_hbmc hbmc_n cptflag_n hh_claim hh_part_b hbmc_hh hbmc_nohh num_hh_claim per_part_b {
replace `x' = 0 if prob_dem==0
}


collapse (max) dem_ffs, by(spid)
tempfile coll
keep if dem_ffs==1
save `coll'

use "E:\nhats\data\NHATS Sensitive\r1_sensitive\NHATS_Round_1_SP_Sen_Dem_File.dta", clear
rename rl1* *
tempfile t1
save `t1'
use "E:\nhats\data\NHATS Sensitive\r5_sensitive\NHATS_Round_5_SP_Sen_Dem_File.dta"
rename rl5* *
tempfile t5
save `t5'
use `t1', clear
append using `t5'

gen racecat=1 if yourrace4==1 | yourrace3==1
replace racecat=2 if yourrace6==1
replace racecat=2 if yourrace5==1
replace racecat=3 if yourrace7==1 | yourrace6==1
replace racecat=4 if yourrace1==1
replace racecat=4 if yourrace2==1
replace racecat=5 if yourrace1==1

forvalues i=1/8 {
gen r`i'=yourrace`i'==1
}
egen mult=rowtotal(r1-r8)
replace racecat=6 if mult>1
replace racecat=7 if missing(racecat)

label define racecat 1 "Amer. Indian/Alaska Native" 2 "Asian" 3 "Hawaiian/Pac Islander" 4 "Black" 5 "White" 6 "Multiple" 7 "Unknown"
label values racecat racecat
keep spid racecat

sort spid racecat
by spid: drop if racecat==7 & _N==2
tempfile t1
save `t1'


use "E:\nhats\data\nhats cleaned\sp_round_1_7.dta", clear
merge m:1 spid using `t1'
keep if sp_ivw==1
keep if prob_dem==1
duplicates drop spid, force
cap drop _m

merge 1:1 spid using "`coll'", keep(match)

tab race*, m
tab racecat, m




H="********Extras*************"


H="HHA zipcode"
use "E:\data\hrs_cleaned\core_00_to_14.dta", clear

/* Get zipcodes from tracker */

local resvars zipcode00 stateusps00 zipcode02 stateusps02 zipcode04 stateusps04 zipcode06 stateusps06 zipcode08 stateusps08 zipcode10 stateusps10 zipcode12 stateusps12 zipcode14 stateusps14 zipcode98 stateusps98

merge m:1 hhid pn using "E:\data\hrs_cleaned\restr_tracker_v2014.dta", keepus(`resvars')

keep if _m==3
drop _m

/* Sort and keep most recent interview */
gsort id -core_year
by id: keep if _n==1


foreach x of local resvars {

*codebook `x'
}


forvalues i = 8(-2)0 {

replace zipcode0`i' ="" if core_year!=200`i' 
replace stateusps0`i' ="" if core_year!=200`i'
/*
codebook zipcode0`i'
codebook stateusps0`i'
*/
}

forvalues i = 14(-2)10 {

replace zipcode`i' ="" if core_year!=20`i' 
replace stateusps`i'="" if core_year!=20`i'
/*
codebook zipcode`i'
codebook stateusps`i'
*/
}


replace zipcode98 ="" if core_year!=1998 
replace stateusps98 ="" if core_year!=1998

/*
codebook zipcode98
codebook stateusps98
*/

gen zipcode = ""
gen stateusps = ""

forvalues i = 14(-2)10 {

replace zipcode = zipcode`i' if zipcode==""
replace stateusps = stateusps`i' if stateusps==""
}

forvalues i=8(-2)0 {

replace zipcode = zipcode0`i' if zipcode==""
replace stateusps = stateusps0`i' if stateusps==""
}

replace zipcode = zipcode98 if zipcode==""
replace stateusps = stateusps98 if stateusps==""

replace zipcode = "99999" if zipcode==""
replace stateusps = "ZZ" if stateusps==""

gen all = 1

/****** carrying forward zip codes from earlier ivw ********/
preserve

keep if stateusps == "ZZ"

local resvars zipcode00 stateusps00 zipcode02 stateusps02 zipcode04 stateusps04 zipcode06 stateusps06 zipcode08 stateusps08 zipcode10 stateusps10 zipcode12 stateusps12 zipcode14 stateusps14 zipcode98 stateusps98

drop `resvars'
merge m:1 hhid pn using "E:\data\hrs_cleaned\restr_tracker_v2014.dta", keepus(`resvars')

keep if _m==3
drop _m

local resvars zipcode00 stateusps00 zipcode02 stateusps02 zipcode04 stateusps04 zipcode06 stateusps06 zipcode08 stateusps08 zipcode10 stateusps10 zipcode12 stateusps12 zipcode14 stateusps14 zipcode98 stateusps98


foreach x of local resvars {

tab `x', m
}

gen prev_zip = ""
gen prev_usps = ""

forvalues i=14(-2)2 {

local j = `i' - 2
if `j'<10 local j="0`j'"

replace prev_zip = zipcode`j' if core_year==20`i' & prev_zip==""
replace prev_usps = stateusps`j' if core_year==20`i' & prev_usps==""
}

replace prev_zip = zipcode98 if core_year==2000
replace prev_usps = stateusps98 if core_year==2000

forvalues i=14(-2)4 {

local j = `i' - 4
if `j'<10 local j="0`j'"

replace prev_zip = zipcode`j' if core_year==20`i' & prev_zip==""
replace prev_usps = stateusps`j' if core_year==20`i' & prev_usps==""
}

replace prev_zip = zipcode98 if core_year==2002 & prev_zip==""
replace prev_usps = stateusps98 if core_year==2002 & prev_usps==""

replace zipcode = prev_zip
replace stateusps = prev_usps

keep if zipcode!=""

tempfile missin
save `missin'

restore

/****** Append back to original data *************/
drop if stateusps=="ZZ"
append using "`missin'"
cap drop _m



merge m:1 zipcode using "E:\data\HBMC_HRS\20190405\HHC_coverage.dta"
drop if _m==2

gen hha_cov = 0
replace hha_cov = 1 if _m==3

preserve


collapse (mean) hha_cov, by(stateusps)

tempfile mea
rename hha_cov hha_per
replace hha_per = hha_per * 100
save `mea'
restore, preserve

replace stateusps = "99"

collapse (sum) hha_cov all, by(stateusps)
tempfile maxusa
save `maxusa'
restore, preserve

replace stateusps = "99"
collapse (mean) hha_cov, by(stateusps)
rename hha_cov hha_per
replace hha_per = hha_per *100
tempfile meausa
save `meausa'
restore


collapse (sum) hha_cov all, by(stateusps)

merge 1:1 stateusps using "`mea'"
drop _m

append using `maxusa'

merge 1:1 stateusps using `meausa', update replace
drop _m



H="HBMC zipcode"


H="JR"
use "E:\nhats\data\Projects\serious_ill\int_data\serious_ill_int_dataset1.dta", clear

keep if community_dwelling==1 & prob_dem==1
bysort spid: egen anyadverse = max(adverse)
preserve
keep if anyadverse==0
gsort spid -wave
by spid: keep if _n==1

codebook spid
tempfile noadverse
save `noadverse'
restore

preserve
keep if adverse==1
codebook spid
gsort spid wave
by spid: keep if _n==1

gen wave_after = 1
replace wave = wave+1

tempfile waveafter
save `waveafter'
restore

merge 1:1 spid wave using "`waveafter'", keepus(wave_after)
keep if _m==3

append using "`noadverse'"

replace tot_hrswk_help_i = 0 if tot_hrswk_help_i ==.
replace tot_hrswk_paid_i = 0 if tot_hrswk_paid_i==.

ttest tot_hrswk_paid_i, by(anyadverse)

local lis3 0.01 0.05 0.1 0.2 0.25 0.5
local m1 = r(mu_1)

foreach i of local lis3 { 

local m4 = `i'*`m1'
local m5 = `m4' + `m1'
di `m5'

power twomeans `m1', n1(1535) n2(469) diff(`m4')
}


/*Income adjustment to $2017 dollars */
gen income_adj=0
replace income_adj= 1.09*aveincome if wave==1
replace income_adj= 1.07*aveincome if wave==2
replace income_adj= 1.06*aveincome if wave==3
replace income_adj= 1.05*aveincome if wave==4
replace income_adj= 1.04*aveincome if wave==5
replace income_adj= 1.02*aveincome if wave==6
replace income_adj = aveincome if wave==7

xtile income_quart_adj=income_adj, nq(4)


local lis3 0.01 0.05 0.1 0.2 0.25 0.5

foreach j of local lis3 {
forvalues i=1/4 {

ttest tot_hrswk_paid_i if income_quart_adj == `i', by(anyadverse)
local m1 = r(mu_1)
local m2 = r(mu_2)
local m3 = `j'*`m1'
local m4 = `m3' + `m1'

di "income quart `i' "
di `j'
di `m4'


local n1 = r(N_1)
local n2 = r(N_2)

power twomeans `m1', n1(`n1') n2(`n2') diff(`m3')
}
}

H="Alina"

use "E:\nhats\data\NHATS Public\round_2\NHATS_Round_2_SP_File.dta", clear 

keep spid eh2meddif eh2medfamdif eh2meddelay eh2medtoomch
gen wave = 2

tempfile burden
save `burden'

use "E:\nhats\data\NHATS cleaned\sp_round_1_7.dta", clear 

merge 1:1 spid wave using "`burden'"

gen tburden = 0
replace tburden = 1 if _m==3
label var tburden "Has treatment burden module"

drop _m
keep if death_year <=2015

age agecat female race_cat education srh aveincome sr_hosp_ind sr_numconditions1 sr_phq2_depressed //
sr_gad2_score dem_3_cat adl_bath_help adl_bed_help adl_dres_help adl_eat_help adl_ins_help adl_toil_help //
marriedpartnered lst10pnds trytolose evrgowalk vigoractv ind_family_helper otherfamily_help_ind otherinformal_help_ind ind_paid_helper n_social_network reg_doc_seen




*keep if wave==2 | lml_ivw_yes==1











H="***************************"


H="PI Notes"
------------As of 5/2/19----------------

There are two tabes. The top table uses HBMC in the same year as interview.
The bottom table carries forward HBMC from previous years, aka cumulative.
The graphs were made with the bottom table.

Death is lagged, so it doesn't overlap with receiving HBMC.

We lost a fair amount of people due to requiring community dwelling + dementia in wave 1 or 5 (new cohort).
We now miss people who were not community dwelling + dementia in wave 1 but become so in later waves and received HBMC.

There are people who receive HBMC and NH in the same year. They either self report having a regular doctor visit, or
had a CPT code. Presumably this happens before they enter NH home, but we only observe them once a year and cannot tell
what happens in March vs June.




----------As of 4/25/19------------

HHA_coverage: Merged HHA coverage from PUF file Jeremy gave me with HRS 1998-2014.
I matched on zip codes and counted at the state level. These are unique respondents,
using their most recent core interview. 150 people did not have a zipcode/state for 
their most recent interview, so I pulled 27 zip/state codes from their core 2 years
prior and 17 from their core 4 years prior. I wasn't sure how far back to go, so I
dropped the remaining 106 with no zip/state within 4 years of most recent core.



HRS & NHATS P01 tables:

I added colums for indicators of multiple claims HBMC, and Ave # of Claims HBMC. There
was a mistake in code that led to undercounting Medicare claims HBMC for a few people, 
so as a result the total Community Dwelling + Dementia unique HBMC went up by 6 and 5 
respectively.






--------As of 4/19/2019---------------------

HRS_HHA_Coverage: Merged HHA coverage from PUF file Jeremy gave me with HRS 1998-2014.
I matched on zip codes and counted at the state level. There are 703 people in HRS 
who had no zip code or State for the year of their interview, so were dropped.

As he pointed out when he showed you the map a couple weeks ago, a lot of the northeastern 
states are not represented in the PUF file, so they are shown as zero in the table.


HRS & NHATS P01 Samples: I've added a table showing unique HBMC per wave/core, and a 3-year/wave
moving average, to help visualize possible projects to 2020. Follow time is the years elapsed between
enrollment and HBMC at interview. For NHATS I counted wave 1 as one year of enrollment for the original cohort,
and I counted wave 5 as 1 year of enrollment for the new people added in the replenished cohort.

HRS was a bit more tricky, so I counted the first wave we observe them as their enrollment. So if someone's first
wave is in 2002 and they are HBMC in 2006, they are counted as 5 years of follow time (2002, 2003, 2004, 2005, 2006).


H="Changelog"
5/03/19 - Changed Longitudinal setup from incident dementia + community dwelling to Dementia + CD + 6m FFS at 1st wave (old cohort) or 2nd wave (new cohort). Omari

4/25/19 - Updated Medicare Part B from type of service code to value code. HRS value code flaky for 1998-2000. NHATS Part B Service code flaky for 2014+.
Added NHATS Wave 7, and indicators for multiple HBMC. Also fixed issue with undercounting HBMC. Omari

4/05/2019 - Created new tables with modified shells to include HHA episodes and % HHA claims paid by Medicare Part B. Omari

3/04/19 - Removed censored/LFU from death classification, and reran tables. Omari

3/01/19 - More tweaks to Sample Size and logitudinal followup. Omari.

2/26/19 - Added 6m FFS restriction to both NHATS and HRS tables.

2/25/19 - Created Incident Dementia tables for HRS + NHATS to show followup data and unique people with HBMC. Omari

2/22/19 - Produced Sample Size tables for NHATS and HRS. Omari