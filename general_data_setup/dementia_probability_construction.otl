= V4 Outline MultiLine NoSorting TabWidth=30

H="Dementia Porbability Construction"
This code will (hopefully) construct dementia probabilities comparable to Hurd's that can be used in the larger sample (as his data is only through '06).



H="sas get tics results"
libname cogn 'E:\data\hrs_public_2012\HRS_Cog';


%macro gettics(w=,year=);

data tics1_&w;
set cogn.cogimp9212a_r;
keep hhid pn core_year prediction_year
r&w.cogtot r&w.status r&w.bwc20 r&w.vp
 r&w.ser7  r&w.scis r&w.cact r&w.pres r&w.mo r&w.dy r&w.yr r&w.dw
 r&w.imrc r&w.dlrc r&w.vocab r&w.mstot 
 r&w.fbwc20 r&w.fvp
 r&w.fser7  r&w.fscis r&w.fcact r&w.fpres r&w.fmo r&w.fdy r&w.fyr r&w.fdw
 r&w.fimrc r&w.fdlrc r&w.fvocab r&w.fmstot;
core_year=&year;
prediction_year=&year+1;
run;

data tics2_&w;
set tics1_&w;
rename r&w.cogtot=TICS_tot;
rename r&w.status=imp_elig_status;
rename r&w.mo=mo;
rename r&w.dy=dy;
rename r&w.yr=yr;
rename r&w.dw=dw;
rename r&w.bwc20=bwc20;
rename r&w.ser7=ser7 ;
rename r&w.scis=scis;
rename r&w.cact=cact;
rename r&w.pres=pres;
rename r&w.imrc=imrc;
rename r&w.dlrc=dlrc;
rename r&w.vp=vp;
rename r&w.vocab=vocab;
rename r&w.mstot=mstot;

rename r&w.fmo=mo_imp;
rename r&w.fdy=dy_imp;
rename r&w.fyr=yr_imp;
rename r&w.fdw=dw_imp;
rename r&w.fbwc20=bwc20_imp;
rename r&w.fser7=ser7_imp;
rename r&w.fscis=scis_imp;
rename r&w.fcact=cact_imp;
rename r&w.fpres=pres_imp;
rename r&w.fimrc=imrc_imp;
rename r&w.fdlrc=dlrc_imp;
rename r&w.fvp=vp_imp;
rename r&w.fvocab=vocab_imp;
rename r&w.fmstot=mstot_imp;



%mend;

%gettics(w=4,year=1998);
%gettics(w=5,year=2000);
%gettics(w=6,year=2002);
%gettics(w=7,year=2004);
%gettics(w=8,year=2006);
%gettics(w=9,year=2008);
%gettics(w=10,year=2010);
%gettics(w=11,year=2012);

data tics_9812;
set tics2_4 tics2_5 tics2_6 tics2_7 tics2_8 tics2_9 tics2_10 tics2_11;
label TICS_tot='TICS Cognition Score, scale 0-35';
run;

proc sort nodupkey; by hhid pn core_year ; run;

/*convert to stata*/
proc export data=tics_9812 
outfile="E:\data\hrs_cleaned\working\tics_9812.dta"
replace;
run;

proc means data=tics_9812; run;

H="Proxies"
libname raw 'E:\data\hrs_public_2012\core';

proc import datafile="E:\data\hrs_public_2012\core\raw\H98PC_R.dta" out=h98pc_r replace;
run;

data core1998a;
set h98pc_r;
keep hhid pn f1389-f1460;
run;

data core19998;
set core1998a;
core_year=1998;
run;

data core2000;
set raw.core2000;
keep core_year hhid pn g1543-g1614;
core_year=2000;
run;

data core2002;
set raw.core2002;
keep core_year hhid pn hd506-hd554;
core_year=2002;
run;

data core2004;
set raw.core2004;
keep core_year hhid pn jd506-jd554;
core_year=2004;
run;

data core2006;
set raw.core2006;
keep core_year hhid pn kd506-kd554;
core_year=2006;
run;

data core2008;
set raw.core2008;
keep core_year hhid pn ld506-ld554;
core_year=2008;
run;

data core2010;
set raw.core2010;
keep core_year hhid pn md506-md554;
core_year=2010;
run;

data core2012;
set raw.core2012;
keep core_year hhid pn nd506-nd554;
core_year=2012;
run;

data proxy;
set core1998 core2000 core2002 core2004 core2006 core2008 core2010 core2012;
run;

proc export data=proxy outfile="E:\data\serious_ill\int_data\proxy.dta" replace; run;


H="Proxy stata"
cd "E:\data\serious_ill\int_data"

use proxy.dta, clear


local fvars 1389 1394 1399 1404 1409 1414 1419 1424 1429 1434 ///
 1439 1444 1448 1451 1454 1457

local i=506
foreach f of local fvars {
	gen fd`i'=f`f'
	gen fd`=`i'+1'=f`=`f'+1'
	gen fd`=`i'+2'=f`=`f'+2'
	local i=`i'+3
}

local gvars 1543 1548 1553 1558 1563 1568 1573 1578 1583 1588 1593 ///
1598 1602 1605 1608 1611

local i=506
foreach g of local gvars {
	gen gd`i'=g`g'
	gen gd`=`i'+1'=g`=`g'+1'
	gen gd`=`i'+2'=g`=`g'+2'
	local i=`i'+3
}
keep hhid pn *d* core_year
tokenize f g h j k l m n
gen cy2=(core_year-1996)/2
local j=1
local k=506
forvalues i=1/16 {
	gen base=.
	gen bet=.
	gen worse=.
	forvalues j=1/8 {
		replace base=``j''d`k' if cy2==`j'
		replace bet=``j''d`=`k'+1' if cy2==`j'
		replace worse=``j''d`=`k'+2' if cy2==`j'
}
	gen pc`i'=3 if base==2
	replace pc`i'=bet if inlist(bet,1,2)
	replace pc`i'=worse if inlist(worse,4,5)
	drop base bet worse
	local k=`k'+3
	local j=`j'+1
}
foreach x in miss total mean {
	egen iq`x'=row`x'(pc1-pc16)
	if "`x'"!="miss" {
	replace iq`x'=. if iqmiss>0
}
}

drop if iqmiss==16
save proxycog.dta, replace


H="get pdem for all and export dataset"


use "E:\data\hrs_cleaned\core_00_to_12.dta", clear
gen prediction_year=core_year+1
merge 1:1 hhid pn core_year using "E:\data\hrs_cleaned\working\tics_9812.dta" , nogen keep(match master)
merge 1:1 hhid pn prediction_year using  "E:\data\hrs_public_2012\dementia\pdem_withvarnames.dta", keepusing(prob)  keep(match master) nogen
merge 1:1 hhid pn core_year using "E:\data\hrs_public_2012\dementia\ADAMS\dementia_dx_adams_wave1_only.dta", nogen
merge m:1 hhid  pn using "E:\data\hrs_cleaned\restricted_tracker_v2012.dta", keepusing(birth_date gender) keep(match master) nogen
merge 1:1 hhid pn core_year using "E:\data\serious_ill\int_data\proxycog.dta", nogen keep(match master) keepusing(iq*)

replace female=gender-1 if !missing(gender)

gen age=floor((c_ivw_date-birth_date)/365.25)
keep if age>=65
gen age_cat=1
replace age_cat=2 if age>=70
replace age_cat=3 if age>=75
replace age_cat=4 if age>=80
replace age_cat=5 if age>=85
replace age_cat=6 if age>=90
tab age_cat, gen(age_cat)
label define age_cat 1 "Age<70" 2 "Age 70-74" 3 "Age 75-79" 4 "Age 80-84" ///
5 "Age 85-89" 6 "Age>=90"
label values age_cat age_cat

gen ed_hs_only=educ==2
gen ed_gt_hs=educ>2
gen n=1
sort id core_year
by id: gen hasn1=!missing(core_year[_n-1])
egen adl_diff_index=rowtotal(adl_diff*)
egen adlmiss=rowmiss(adl_diff*)
local iadl iadl_diff_mp iadl_diff_gr iadl_diff_ph iadl_diff_rx iadl_diff_m 
sum n `iadl'
egen iadl_diff_index=rowtotal(`iadl')
egen iadlmiss=rowmiss(`iadl')
replace adlmiss=1 if adlmiss>1
replace iadlmiss=1 if iadlmiss>1
*replace adl_diff_index=. if missing(adl_index_core)
gen dates=mo+dy+yr+dw
gen dates_imp=mo_imp==1 |dy_imp==1 | yr_imp==1 | dw_imp==1
gen iqmissany=iqmiss>0 if !missing(iqmiss)
gen iqmissgt2=iqmiss>2 if !missing(iqmiss)
local cogvars proxy_core  imrc dlrc ser7 bwc20 dates scis cact pres vp adl_diff_index ///
iadl_diff_index adlmiss iadlmiss iqmean iqmissgt2 iqmissany
sum n `cogvars' if !proxy & !missing(dx_a)
sum n `cogvars' if proxy & !missing(dx_a)

foreach x of local cogvars {
sort id core_year
qui by id: gen prev`x'=`x'[_n-1]
qui gen ch_`x'=`x'-prev`x'
if inlist("`x'","imrc","dlrc","ser7","bwc20","dates","scis","cact","pres","vp") ///
qui gen miss`x'=`x'_imp==1
if !inlist("`x'","imrc","dlrc","ser7","bwc20","dates","scis","cact","pres","vp") ///
qui gen miss`x'=`x'==.
qui gen missprev`x'=prev`x'==.
if inlist("`x'","imrc","dlrc","ser7","bwc20","dates","scis","cact","pres","vp") ///
& proxy[_n-1]==0 qui replace missprev`x'=`x'_imp[_n-1]==1

qui replace ch_`x'=0 if ch_`x'==.
qui replace prev`x'=`x' if prev`x'==.
sum prev`x' if proxy==1
replace prev`x'=r(mean) if missprev`x' & proxy==1 & prevproxy==1
}
gen adliadlmiss=adlmiss | iadlmiss
*replace adl_diff_index=. if adlmiss>=2
*replace iadl_diff_index=. if iadlmiss>=2
tempfile this
save `this'

/*note-most missing variables excluded due to collinearity*/
local regvars /*c.age##c.age*/ age_cat3 age_cat4 age_cat5 age_cat6 ed_hs_only ed_gt_hs female ///
adl_diff_index iadl_diff_index ch_adl_diff ch_iadl_diff  dates bwc20 ///
ser7 scis cact pres imrc dlrc ch_dates ch_bwc20 ch_ser7 ch_scis ch_cact ch_pres ///
ch_imrc ch_dlrc missbwc20 missser7 misssci misscact misspres missimrc ///
missdlrc missdates adliadlmiss 

local proxyvars /*c.age##c.age*/ age_cat3 age_cat4 age_cat5 age_cat6 ed_hs_only ed_gt_hs female ///
adl_diff_index iadl_diff_index ch_adl_diff ch_iadl_diff iqmean /*iqmissgt2*/ iqmissany ch_iqmean ///
prevproxy prevdates prevser7 prevpres previmrc prevdlrc ///
/*prevcact prevscis prevbwc20*/ missprevdates missprevpres missprevimrc missprevdlrc ///
adliadlmiss /*previqmissgt2*/ previqmissany

sum `regvars' if !proxy & !missing(dx_a)
sum `proxyvars' if proxy & !missing(dx_a)


oprobit dx `regvars' if proxy==0
predict pself if proxy==0
predict pself2 if proxy==0, outcome(#2)
predict pself3 if proxy==0, outcome(#3)
oprobit dx `proxyvars' if proxy==1
predict pdem if proxy==1
predict pdem2 if proxy==1, outcome(#2)
predict pdem3 if proxy==1, outcome(#3)

replace pdem=pself if proxy==0
replace pdem2=pself2 if proxy==0
replace pdem3=pself3 if proxy==0
gen ldem=1 if !missing(pdem)
replace ldem=2 if pdem2>pdem
replace ldem=3 if pdem3>pdem2 & pdem3>pdem
gen likely_dem=ldem==1 if !missing(pdem)
gen likely_cind=ldem==2
gen likely_normal=ldem==3
preserve
keep id proxy pdem* prob_dem dx_adams core_year ldem likely_*
rename prob_dem prob_hurd
save E:\data\hrs_public_2012\dementia\pdem_withvarnames_ebl, replace


H="***********************************"


H="Look at dementia dx in ADAMS, full sample, and decents list"
/* I want to get the dementia diagnosis for everybody one and two years before their interview date and one and two years before their death date.  I will get number of diagnoses, and number of each diagnosis type.  Do they come from inpatient or outpatient?*/

libname dem 'E:\data\Evan_SAS_practice';

libname medi 'E:\data\CMS_DUA_24548_2012';

libname serill 'E:\data\serious_ill\int_data';

libname deced 'E:\data\spouse_intensive\int_data';



H="get claims & dxs"
/*get list of ids, bids, & dates, using the intermediate datasets created for serious illness and spouse intensive procedure*/
/* I want to get the dementia diagnosis for everybody one and two years before their interview date and one and two years before their death date.  I will get number of diagnoses, and number of each diagnosis type.  Do they come from inpatient or outpatient?*/


proc import datafile="E:\data\serious_ill\int_data\core_ids_1yr_criteria_5_sample1.dta" 
out=interviews1 replace;
run;

proc import datafile="E:\data\hrs_public_2012\dementia\ADAMS\dementia_dx_adams_wave1_old.dta" 
out=interviews1a replace;
run;

proc sql;
create table interviews2 as select a.*,b.bid_hrs
from 
interviews1a a 
left join
interviews1 b
on a.id=b.id and a.core_year=b.core_year;
quit;



data interviews;
set interviews2;
index_date=adams_date;
run;

/*get claims 2 years before*/
%macro claims (source=,name=,su=);

proc sql;
create table &name._&source._meet_&su.a as select *
from medi.&source._2000_2012 a inner join
&name. b
on trim(left(a.bid_hrs_21))=trim(left(b.bid_hrs))
and ((admit_date>=(index_date-&su.) and index_date>=admit_date) 
or (disch_date>=(index_date-&su.) and disch_date<=index_date));
quit;

data &name._&source._meet_&su.;
set &name._&source._meet_&su.a;
source="&source";
run;
%mend;

%claims(source=mp,name=interviews,su=365);
%claims(source=op,name=interviews,su=365);
%claims(source=pb,name=interviews,su=365);
%claims(source=hh,name=interviews,su=365);
%claims(source=hs,name=interviews,su=365);
%claims(source=dm,name=interviews,su=365);




/**************************************************************************/
/* ********************* S Diagnosis Lists   ******************************/
/**************************************************************************/

%macro dx_time_range (range1=,name=,su=);
/*pulls just dx codes from carrier claims*/
data pb_last_&su._dx(keep=bid_hrs_21 id diag source index_date);
set &name._pb_meet_&su.(keep=bid_hrs_21 id PDGNS_CD DGNSCD01-DGNSCD12 source index_date);
array dx PDGNS_CD DGNSCD01-DGNSCD12;
do over dx;
diag=dx ;
output;
end;
run;
proc sort data=pb_last_&su._dx out=pb_last_&su._dx2 nodupkey;
by bid_hrs_21 id diag;
run;

/*outpatient claims*/
data op_last_&su._dx(keep=bid_hrs_21 id diag source index_date);
set &name._op_meet_&su.(keep=bid_hrs_21 id PDGNS_CD DGNSCD01-DGNSCD25 source index_date);
array dx PDGNS_CD DGNSCD01-DGNSCD25 ;
do over dx;
diag=dx ;
output;
end;
run;
proc sort data=op_last_&su._dx out=op_last_&su._dx2 nodupkey;
by bid_hrs_21 id diag;
run;

/*medpar claims*/
data mp_last_&su._dx(keep=bid_hrs_21 id diag source index_date);
set &name._mp_meet_&su.(keep=bid_hrs_21 id AD_DGNS DGNS_CD01-DGNS_CD25 source index_date);
array dx D_DGNS DGNS_CD01-DGNS_CD25 ;
do over dx;
diag=dx ;
output;
end;
run;
proc sort data=mp_last_&su._dx out=mp_last_&su._dx2 nodupkey;
by bid_hrs_21 id diag;
run;

/*dme claims*/
data dm_last_&su._dx(keep=bid_hrs_21 id diag source index_date);
set &name._dm_meet_&su.(keep=bid_hrs_21 id PDGNS_CD DGNSCD01-DGNSCD12 index_date source);
array dx PDGNS_CD DGNSCD01-DGNSCD12 ;
do over dx;
diag=dx ;
output;
end;
run;
proc sort data=dm_last_&su._dx out=dm_last_&su._dx2 nodupkey;
by bid_hrs_21 id diag;
run;

/*home health agency*/
data hh_last_&su._dx(keep=bid_hrs_21 id diag source index_date);
set &name._hh_meet_&su.(keep=bid_hrs_21 id PDGNS_CD DGNSCD01-DGNSCD25 index_date source);
array dx PDGNS_CD DGNSCD01-DGNSCD25 ;
do over dx;
diag=dx ;
output;
end;
run;
proc sort data=hh_last_&su._dx out=hh_last_&su._dx2 nodupkey;
by bid_hrs_21 id diag;
run;

/*hospice*/
data hs_last_&su._dx(keep=bid_hrs_21 id diag source index_date);
set &name._hs_meet_&su.(keep=bid_hrs_21 id PDGNS_CD DGNSCD01-DGNSCD25 index_date source);
array dx PDGNS_CD DGNSCD01-DGNSCD25 ;
do over dx;
diag=dx ;
output;
end;
run;
proc sort data=hs_last_&su._dx out=hs_last_&su._dx2 nodupkey;
by bid_hrs_21 id diag;
run;

/*set diag variable length = 7 chars since that's the max length from the mc claims
Need to do this because length varies across the different mc claim types*/
data hs_last_&su._dx3;
length diag $7;
set hs_last_&su._dx2;
run;
data hh_last_&su._dx3;
length diag $7;
set hh_last_&su._dx2;
run;
data mp_last_&su._dx3;
length diag $7;
set mp_last_&su._dx2;
run;
data dm_last_&su._dx3;
length diag $7;
set dm_last_&su._dx2;
run;
data op_last_&su._dx3;
length diag $7;
set op_last_&su._dx2;
run;
data pb_last_&su._dx3;
length diag $7;
set pb_last_&su._dx2;
run;

data dx_all_last_&su.;
set hs_last_&su._dx3
hh_last_&su._dx3
mp_last_&su._dx3
dm_last_&su._dx3
op_last_&su._dx3
pb_last_&su._dx3;
run;

proc sort data=dx_all_last_&su.(where=(diag~="")) out=&name._dx_&range1._&su. nodupkey;
by bid_hrs_21 id diag;
run;

%mend;

/*run macro to create data files spo_mc_i.dx_0d_n6m spo_mc_i.dx_0d_n12m and spo_mc_i.dx_0d_n24m */
%dx_time_range (range1=0,name=interviews,su=365);


/*creates indicators for each of the Elixhauser comorbidities
based on the dx codes lists 6, 12, and 24m before and after R's death

resulting dataset is spo_mc_i.hrs_elix*/

/*rename macro - called within the elixhauser macro
to add time suffix to variables

lib=library
dsn=dataset name
pre=suffix to be added to all of the variable names
*/

%macro rename(lib,dsn,pre);
options pageno=1 nodate;
proc contents data=&lib..&dsn;
title "Before Renaming All Variables";
run;

proc sql noprint;
select nvar into :num_vars
from dictionary.tables
where libname="&LIB" and
memname="&DSN";
select distinct(name) into :var1-
:var%TRIM(%LEFT(&num_vars))
from dictionary.columns
where libname="&LIB" and
memname="&DSN";
quit;
run;

proc datasets library=&LIB;
modify &DSN;
rename
%do i=1 %to &num_vars;
&&var&i=&&var&i.._&pre 
%end;
;
quit;
run;
options pageno=1 nodate;
proc contents data=&lib..&dsn;
title "After Renaming All Variables";
run;
%mend rename;



/*Elixhauser index macro
Note includes additional 2 comorbidities: Dementia and Coronary Artery Disease*/

%macro elixhauser(range1=,name=,su=);

data &name._dem_dx_comor_&su;
set &name._dx_&range1._&su(rename=(diag=dx_0));
dx=trim(left(dx_0));

if dx~="" then do;


dem_dx=0;
*do over dx;
*dementia;
	if (substr(dx,1,4) in ('3310','3311','3312','2900','2901',
             '2902','2903','2912','2948','2949') or
		substr(dx,1,5) in ('29410','29411','29040','29041','29042','29043')) 
				and dem_dx=0 
          then dem_dx=1;




end;
run;

%mend;








/*calls rename macro*/
*%rename(WORK,TEST,&range1._&su);

/*rename r&s BID variables*/
/*data spo_mc_i.elix_&range1._&su._2
	(rename =(r_id_&range1._&su=r_id)
	rename =(s_BID_hrs_&range1._&su=s_BID_hrs));
set test;
keep s_BID_hrs_&range1._&su r_id_&range1._&su s_comorb:;
run;

proc sort data=spo_mc_i.elix_&range1._&su._2;
by s_bid_hrs r_id;
run;

%mend;

/*run macro to get elixhauser comorbidities 6, 12, 24m pre and post death
resulting datasets are spo_int.elix_0d_x#m_2
x = n=before, p=after death
# = 6, 12, or 24 for time window (months)*/


%elixhauser(range1=0,name=interviews,su=365);




proc export data=interviews_dem_dx_comor_365 outfile="E:\data\serious_ill\int_data\adams_dem_dx.dta" replace; run;



H="stata to bring into datasets and compare"
use "E:\data\serious_ill\int_data\interviews_dem_dx.dta", clear
drop if dem_dx==0
foreach x in mp op pb hs hh dm {
gen s`x'=source=="`x'"
by id index_date, sort: egen `x'=max(s`x')
drop s`x'
}
rename index_date c_ivw_date
drop source dx dx_0
duplicates drop
by id c_ivw_date: gen num=_N
merge 1:1 id c_ivw_date using "E:\data\serious_ill\int_data\core_ids_1yr_criteria_5_sample1", gen(ivwmerge)
gen prediction_year=core_year+1 
merge 1:1 hhidpn prediction_year using "E:\data\hrs_public_2012\dementia\pdem_withvarnames.dta", gen(probmerge) keep(match master)
merge 1:1 id core_year using "E:\data\hrs_public_2012\dementia\ADAMS\dementia_dx_adams_wave1_only.dta", gen(adamsmerge) 



H="interviews"
use "E:\data\serious_ill\int_data\interviews_dem_dx.dta", clear
drop if dem_dx==0
destring dx, replace
foreach x in mp op pb hs hh dm {
gen s`x'=source=="`x'"
by id index_date, sort: egen `x'=max(s`x')
drop s`x'
}

rename index_date c_ivw_date
*drop source dx dx_0
duplicates drop
by id c_ivw_date: gen num=_N
merge m:1 id c_ivw_date using "E:\data\serious_ill\int_data\core_ids_1yr_criteria_5_sample1", gen(ivwmerge)
gen prediction_year=core_year+1 
merge m:1 hhidpn prediction_year using "E:\data\hrs_public_2012\dementia\pdem_withvarnames.dta", gen(probmerge) keep(match master)
merge m:1 id core_year using "E:\data\hrs_public_2012\dementia\ADAMS\dementia_dx_adams_wave1_only.dta", gen(adamsmerge) 
gen pdem=prob_dementia>=.5 if prob_dementia!=.
tab dx 
scalar rn=r(r)+1

preserve
keep if dem_dx==1 & pdem!=.

foreach q in 1 2 {
mat dx`q'=J(rn,4,.)
local r=1
sum dem_dx
mat dx`q'[`r',1]=r(N)
mat dx`q'[`r',2]=(r(N)/_N)*100
sum pdem
mat dx`q'[`r',3]=r(mean)*r(N)
mat dx`q'[`r',4]=r(mean)*100
local r=`r'+1
	foreach x of numlist 2900 2901 2902 2903 2912 2948 2949 3310 3311 3312 29000 29010 ///
	29011 29012 29013 29020 29021 29040 29041 29042 29043 29410 29411 29481 33100 33111 33119 {
		sum dem_dx if dx==`x'
		mat dx`q'[`r',1]=r(N)
		mat dx`q'[`r',2]=(r(N)/_N)*100
		sum pdem if dx==`x'
		mat dx`q'[`r',3]=r(mean)*r(N)
		mat dx`q'[`r',4]=r(mean)*100
		local r=`r'+1
}
	

mat rownames dx`q'=Total 2900 2901 2902 2903 2912 2948 2949 3310 3311 3312 29000 29010 ///
29011 29012 29013 29020 29021 29040 29041 29042 29043 29410 29411 29481 33100 33111 33119

frmttable, statmat(dx`q') ctitles("" "Number dx" "% of total dx" "Number with prob>.5" "% with prob>.5") ///
sdec(0,2,0,2)

*capture drop source dx dx_0 
duplicates drop id c_ivw_date, force

mat source`q'=J(7,4,.)
local r=1

sum dem_dx
mat source`q'[`r',1]=r(N)
mat source`q'[`r',2]=(r(N)/_N)*100
sum pdem
mat source`q'[`r',3]=r(mean)*r(N)
mat source`q'[`r',4]=r(mean)*100
local r=2
foreach x in mp op pb hs hh dm {
	sum dem_dx if `x'==1
	mat source`q'[`r',1]=r(N)
	mat source`q'[`r',2]=(r(N)/_N)*100
	sum pdem if `x'==1
	mat source`q'[`r',3]=r(mean)*r(N)
	mat source`q'[`r',4]=r(mean)*100
	local r=`r'+1
}

mat rownames source`q'=Total MP OP PB HS HH DM 

frmttable, statmat(source`q') ctitles("" "Number dx" "% of total dx" "Number with prob>.5" "% with prob>.5") ///
sdec(0,2,0,2)

keep if num==1
}

foreach x in 1 {
frmttable using "E:\data\serious_ill\logs\Dem_dx_interviews.rtf", statmat(dx1) ctitles("" "Number dx" ///
 "% of total dx" "Number with prob>.5" "% with prob>.5") replace ///
sdec(0,2,0,2) title("Dementia Diagnoses & Hurd Probability, 1yr pre core interview, all diagnoses") ///
note("Restricted to instances with 12m FFS with at least one diagnosis & non-missing probability")

frmttable using "E:\data\serious_ill\logs\Dem_dx_interviews.rtf", statmat(dx2) ctitles("" "Number dx" "% of total dx" "Number with prob>.5" "% with prob>.5") ///
sdec(0,2,0,2) title("Dementia Diagnoses & Hurd Probability, 1yr pre core interview, unique diagnosis") ///
note("Restricted to instances with 12m FFS with only one diagnosis & non-missing probability") ///
addtable

frmttable using "E:\data\serious_ill\logs\Dem_dx_interviews.rtf", ///
statmat(source1) ctitles("" "Number ivws" "% of total" ///
"Number with prob>.5" "% with prob>.5") addtable ///
sdec(0,2,0,2) title("Dx Source & Hurd Probability, 1yr pre core interview, all diagnoses") ///
note("Restricted to instances with 12m FFS with at least one diagnosis & non-missing probability")


frmttable using "E:\data\serious_ill\logs\Dem_dx_interviews.rtf", statmat(source2) ctitles("" ///
"Number of ivws" "% of total" "Number with prob>.5" "% with prob>.5") addtable ///
sdec(0,2,0,2) title("Dx Source & Hurd Probability, 1yr pre core interview, unique diagnosis") ///
note("Restricted to instances with 12m FFS with only one diagnosis & non-missing probability")
}



H="decedents"
use "E:\data\spouse_intensive\int_data\spouse_data_full.dta", clear

keep r_id r_death_date_e comorb_31 r_core_year_n1 r_hhidpn_n1
rename (r_id r_hhidpn_n1 r_core_year_n1) (id hhidpn core_year)
gen index_date=r_death_date_e
merge 1:m id index_date using "E:\data\serious_ill\int_data\decedents_dem_dx.dta", gen(dodmerge)
tostring id, replace
gsort +id -dem_dx
by id: drop if dem_dx==0 & _n!=1
replace dx="" if dem_dx!=1
destring dx, replace
foreach x in mp op pb hs hh dm {
gen s`x'=source=="`x'"
by id index_date, sort: egen `x'=max(s`x')
drop s`x'
}

rename index_date death_date
*drop source dx dx_0
duplicates drop
by id death_date: gen num=_N
gen prediction_year=core_year+1 
merge m:1 hhidpn prediction_year using "E:\data\hrs_public_2012\dementia\pdem_withvarnames.dta", gen(probmerge) keep(match master)
merge m:1 id core_year using "E:\data\hrs_public_2012\dementia\ADAMS\dementia_dx_adams_wave1_only.dta", gen(adamsmerge) 
gen pdem=prob_dementia>=.5 if prob_dementia!=.
tab dx 
scalar rn=r(r)+1

preserve
keep if dem_dx==1 & pdem!=.

foreach q in 1 2 {
mat dx`q'=J(rn,4,.)
local r=1
sum dem_dx
mat dx`q'[`r',1]=r(N)
mat dx`q'[`r',2]=(r(N)/_N)*100
sum pdem
mat dx`q'[`r',3]=r(mean)*r(N)
mat dx`q'[`r',4]=r(mean)*100
local r=`r'+1
	foreach x of numlist 2900 2901 2903 2912 2948 2949 3310 3312 29000 29010 ///
	29011 29012 29013 29020 29021 29040 29041 29042 29043 29410 29411 29480 33100 33119 {
		sum dem_dx if dx==`x'
		mat dx`q'[`r',1]=r(N)
		mat dx`q'[`r',2]=(r(N)/_N)*100
		sum pdem if dx==`x'
		mat dx`q'[`r',3]=r(mean)*r(N)
		mat dx`q'[`r',4]=r(mean)*100
		local r=`r'+1
}
	

mat rownames dx`q'=Total 2900 2901 2903 2912 2948 2949 3310 3312 29000 29010 ///
	29011 29012 29013 29020 29021 29040 29041 29042 29043 29410 29411 29480 33100 33119 

frmttable, statmat(dx`q') ctitles("" "Number dx" "% of total dx" "Number with prob>.5" "% with prob>.5") ///
sdec(0,2,0,2)

duplicates drop id death_date, force

mat source`q'=J(7,4,.)
local r=1

sum dem_dx
mat source`q'[`r',1]=r(N)
mat source`q'[`r',2]=(r(N)/_N)*100
sum pdem
mat source`q'[`r',3]=r(mean)*r(N)
mat source`q'[`r',4]=r(mean)*100
local r=2
foreach x in mp op pb hs hh dm {
	sum dem_dx if `x'==1
	mat source`q'[`r',1]=r(N)
	mat source`q'[`r',2]=(r(N)/_N)*100
	sum pdem if `x'==1
	mat source`q'[`r',3]=r(mean)*r(N)
	mat source`q'[`r',4]=r(mean)*100
	local r=`r'+1
}

mat rownames source`q'=Total MP OP PB HS HH DM 

frmttable, statmat(source`q') ctitles("" "Number dx" "% of total dx" "Number with prob>.5" "% with prob>.5") ///
sdec(0,2,0,2)

keep if num==1
}

foreach x in 1 {
frmttable using "E:\data\serious_ill\logs\Dem_dx_decedents.rtf", statmat(dx1) ctitles("" "Number dx" "% of total dx" ///
"Number with prob>.5" "% with prob>.5") replace ///
sdec(0,2,0,2) title("Dementia Diagnoses & Hurd Probability, 1yr pre death, all diagnoses") ///
note("Restricted to instances with 12m FFS with at least one diagnosis & non-missing probability")

frmttable using "E:\data\serious_ill\logs\Dem_dx_decedents.rtf", statmat(dx2) ctitles("" "Number dx" ///
"% of total dx" "Number with prob>.5" "% with prob>.5") addtable ///
sdec(0,2,0,2) title("Dementia Diagnoses & Hurd Probability, 1yr pre death, unique diagnosis") ///
note("Restricted to instances with 12m FFS with only one diagnosis & non-missing probability")

frmttable using "E:\data\serious_ill\logs\Dem_dx_decedents.rtf", statmat(source1) ctitles("" ///
"# Decedents" "% of total" "Number with prob>.5" "% with prob>.5") addtable ///
sdec(0,2,0,2) title("Dx Source & Hurd Probability, 1yr pre death, all diagnoses") ///
note("Restricted to instances with 12m FFS with at least one diagnosis & non-missing probability")


frmttable using "E:\data\serious_ill\logs\Dem_dx_decedents.rtf", statmat(source2) ctitles("" ///
"# Decedents" "% of total" "Number with prob>.5" "% with prob>.5") addtable ///
sdec(0,2,0,2) title("Dx Source & Hurd Probability, 1yr pre death, unique diagnosis") ///
note("Restricted to instances with 12m FFS with only one diagnosis & non-missing probability")
}


H="recreate hurd tables"
use  E:\data\hrs_public_2012\dementia\ADAMS\dementia_dx_adams if !missing(dx), clear
rename dx_a dx1
rename core_year core_prior_to_adams
gen core_year=core_prior if adams_wave==1
replace core_year=2*(floor(adams_year/2)) if adams_wave>1
replace core_year=2006 if adams_wave==3
duplicates tag id core_year, gen(dup)
replace core_year=core_year+2 if dup==1 & adams_wave>1
merge 1:1 id core_year using E:\data\hrs_public_2012\dementia\pdem_withvarnames_ebl, nogen keep(match)
*merge 1:1 id core_year using E:\data\hrs_cleaned\core_00_to_12
*merge m:1 hhid  pn using "E:\data\hrs_cleaned\restricted_tracker_v2012.dta", keepusing(birth_date gender) keep(match master) nogen

gen stratum=.
forvalues i=0/9 {
replace stratum =`=`i'+1' if pdem>0.`i' & pdem<=0`=.`i'+.1'
}

xtile bin=pdem if adams_wave==1, nq(10)
mat tab=J(11,6,.)
local r=1
local c=1
forvalues i=1/10 {
	mat tab[`r',1]=`i'
	sum pdem if bin==`i'
	mat tab[`r',2]=r(N)
	mat tab[`r',3]=r(mean)
	mat tab[`r',5]=r(mean)*r(N)
	sum deme if bin==`i'
	mat tab[`r',4]=r(mean)
	mat tab[`r',6]=r(mean)*r(N)
	local r=`r'+1
}
foreach i in 0 {
	mat tab[`r',1]=`i'
	sum pdem if !missing(dx_a)
	mat tab[`r',2]=r(N)
	mat tab[`r',3]=r(mean)
	mat tab[`r',5]=r(mean)*r(N)
	sum deme if !missing(dx_a) & !missing(pdem)
	mat tab[`r',4]=r(mean)
	mat tab[`r',6]=r(mean)*r(N)
	local r=`r'+1
}

frmttable using "E:\data\hrs_public_2012\dementia\hurd_replication_tables.rtf", replace statmat(tab) ctitles("Bin" "N" "Fitted Prob" "Actual prob" ///
"Estimated cases" "Actual cases") sdec(0,0,3,3,3,0) ///
title(Replication Hurd Table S1)


by id, sort: egen adx=max(dx_a)
label values adx dx_adams
preserve
keep if adams_wave==3 & !missing(ldem)

tab adx dx1, row nofreq
tab adx ldem, row nofreq

mat tab=J(3,4,.)
local r=1
local c=2

foreach x in 3 2 "3,2" {
	sum adx if inlist(adx,`x')
	mat tab[`r',1]=r(N)
	local denom=r(N)
	foreach y in 3 2 1 {
		sum adx if dx1==`y' & inlist(adx,`x')
		mat tab[`r',`c']=(r(N)/`denom')*100
		local c=`c'+1
}
	local r=`r'+1
	local c=2
}

mat rownames tab=Normal CIND Total

frmttable using "E:\data\hrs_public_2012\dementia\hurd_replication_tables.rtf", addtable statmat(tab) ctitles("" "" "Wave C" "" \"Wave A" "N" "Normal" "CIND" ///
"Demented") title(Replication Hurd table S4) sdec(0,1,1,1)

mat tab=J(4,3,.)
local r=1
local c=1

foreach x in 3 2 "" {
	foreach y in 3 2 1 "1,2,3" {
		sum pdem`x' if inlist(dx1,`y') 
		mat tab[`r',`c']=r(mean)*100
		local r=`r'+1
}
	local c=`c'+1
	local r=1
}


mat rownames tab=Normal CIND Demented Total

frmttable using "E:\data\hrs_public_2012\dementia\hurd_replication_tables.rtf", addtable statmat(tab) ctitles("Wave C" "" "Model" "" \"" "Normal" "CIND" ///
"Demented") title(Replication Hurd table S5) sdec(1)
